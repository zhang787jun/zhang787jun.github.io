<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>CTC loss Function - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Computer_Vision">Computer_Vision</a>&nbsp;»&nbsp;<a href="/Wiki/#-Algorithm_Theory">Algorithm_Theory</a>&nbsp;»&nbsp;<a href="/Wiki/#-场景">场景</a>&nbsp;»&nbsp;<a href="/Wiki/#-OCR">OCR</a>&nbsp;»&nbsp;<a href="/Wiki/#-字符识别">字符识别</a>&nbsp;»&nbsp;CTC loss Function</div>
</div>
<div class="clearfix"></div>
<div id="title">CTC loss Function</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1-ctc">1. CTC 是什么</a></li>
<li><a href="#2">2. 使用场景?</a></li>
<li><a href="#3">3. 原理</a><ul>
<li><a href="#31-softmax">3.1. Softmax 之后</a></li>
</ul>
</li>
<li><a href="#4">4. 关键</a><ul>
<li><a href="#41-ctc-loss">4.1. CTC Loss</a><ul>
<li><a href="#411">4.1.1. 基本步骤</a></li>
</ul>
</li>
<li><a href="#42-ctc-decoder">4.2. CTC decoder</a><ul>
<li><a href="#421">4.2.1. 主要解码方法</a></li>
<li><a href="#422">4.2.2. 基本步骤</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#5">5. 实践</a><ul>
<li><a href="#51-tensorflow">5.1. Tensorflow</a></li>
</ul>
</li>
<li><a href="#6">6. 参考资料</a></li>
</ul>
</div>
<h1 id="1-ctc">1. CTC 是什么</h1>
<p>CTC 的全称是<code>Connectionist Temporal Classification</code>。</p>
<h1 id="2">2. 使用场景?</h1>
<p>这个方法主要是解决神经网络label 和output <strong>不对齐的问题</strong>（Alignment problem）。</p>
<h1 id="3">3. 原理</h1>
<p>CTC是借鉴了隐马尔科夫模型(Hidden Markov Nodel)的Forward-Backward算法思路，是利用动态规划的思路计算CTC-Loss及其导数的。</p>
<h2 id="31-softmax">3.1. Softmax 之后</h2>
<h1 id="4">4. 关键</h1>
<h2 id="41-ctc-loss">4.1. CTC Loss</h2>
<h3 id="411">4.1.1. 基本步骤</h3>
<p>训练神经网络需要计算<code>loss function</code> ， 与其他常见的<code>loss function</code>不同，计算<strong>CTC loss</strong>需要2步：<br />
1. 计算所有可能的序列组合的概率和</p>
<blockquote>
<p>We first need to sum over probabilities of all possible alignments of the text present in the image.<br />
2. 取负对数<br />
Then take the negative logarithm of this to calculate the loss.</p>
</blockquote>
<div class="hlcode"><pre>
</pre></div>


<h2 id="42-ctc-decoder">4.2. CTC decoder</h2>
<p>在推理阶段，需要 <code>CTC decoder</code>从神经网络的输出获得文本。<br />
训练和的 Nw 可以用来预测新的样本输入对应的输出字符串，这涉及到解码。<br />
按照最大似然准则，最优的解码结果为：</p>
<p>$$h(x)=argmax_{l∈L≤T} p(l|x)$$</p>
<p>然而，上式不存在已知的高效解法。下面介绍几种实用的近似破解码方法。</p>
<h3 id="421">4.2.1. 主要解码方法</h3>
<p>这里主要有2种分类方法 (decoding method)：<br />
1. <code>Best path decoding</code>.  按照正常分类问题， 那就是概率最大的sequence 就是分类器的输出。 这个就是用每一个 time step的输出做最后的结果。 但是这样的方法不能保证一定会找到最大概率的sequence. <br />
2. <code>prefix search decoding</code>.  这个方法据说给定足够的计算资源和时间， 能找到最优解。 但是复杂度会指数增长 随着输入sequence 长度的变化。  这里推荐用有限长度的prefix search decode 来做。 但是具体考虑多长的sequence做判断 还需具体问题具体分析。 这里的理论基础和就是 每一个node  都是condition 在上一个输出的前提下  算出整个序列的概率。</p>
<h3 id="422">4.2.2. 基本步骤</h3>
<ol>
<li>选取每个步长概率最高的字符<blockquote>
<p>Takes the characters with the highest probability for each time step.</p>
</blockquote>
</li>
<li>去重和空白符号<br />
    &gt;Remove the duplicate characters and then remove the blank character from the outputs.</li>
</ol>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup><sup id="fnref:2"><a class="footnote-ref" href="#fn:2" rel="footnote">2</a></sup></p>
<h1 id="5">5. 实践</h1>
<h2 id="51-tensorflow">5.1. Tensorflow</h2>
<div class="hlcode"><pre><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">(</span>
    <span class="n">labels</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">sequence_length</span><span class="p">,</span>
    <span class="n">preprocess_collapse_repeated</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">ctc_merge_repeated</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">ignore_longer_outputs_than_inputs</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">time_major</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</pre></div>


<p>labels：int32 类型的稀疏向量<br />
inputs：3维的float向量，如果time_major为默认的，那么其形状为[max_time, batch_size, num_classes]，把LSTM输出的第0维和第1维换一下即可。另外，如同TensorFlow源码解读之greedy search及beam search中所讲的那样，输入值是经过logit处理的变量。<br />
sequence_length：是一个int32列表，维度为 batch_size，里面每个值的大小为系列的长度。</p>
<h1 id="6">6. 参考资料</h1>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Connectionist Temporal Classification - Labeling Unsegmented Sequence Data with Recurrent Neural Networks: Graves et al., 2006 <a href="http://www.cs.toronto.edu/~graves/icml_2006.pdf">(pdf)</a>&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p><a href="https://blog.csdn.net/JackyTintin/article/details/79425866">CSDN: CTC 原理及实现</a>&#160;<a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>