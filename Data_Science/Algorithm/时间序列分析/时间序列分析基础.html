<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>时间序列数据分析、处理及预测 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Science">Data_Science</a>&nbsp;»&nbsp;<a href="/Wiki/#-Algorithm">Algorithm</a>&nbsp;»&nbsp;<a href="/Wiki/#-时间序列分析">时间序列分析</a>&nbsp;»&nbsp;时间序列数据分析、处理及预测</div>
</div>
<div class="clearfix"></div>
<div id="title">时间序列数据分析、处理及预测</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 前言</a></li>
<li><a href="#2">2. 随机变量的数学统计特征</a><ul>
<li><a href="#21">2.1. 单变量的数学特征</a><ul>
<li><a href="#211-">2.1.1. 期望--中心度</a></li>
<li><a href="#212-">2.1.2. 方差--分散度</a></li>
</ul>
</li>
<li><a href="#22">2.2. 多变量的数学特征</a><ul>
<li><a href="#221-">2.2.1. 协方差--关联方向协同性</a></li>
<li><a href="#222-">2.2.2. 相关系数--关联紧密性</a><ul>
<li><a href="#2221">2.2.2.1. 皮尔逊相关系数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#23">2.3. 单变量序列的数学特征</a><ul>
<li><a href="#231-">2.3.1. 均值函数--中心度</a></li>
<li><a href="#232">2.3.2. 方差</a></li>
<li><a href="#233">2.3.3. 自相关性</a><ul>
<li><a href="#2331">2.3.3.1. 依据自相关性的序列分类</a><ul>
<li><a href="#23311">2.3.3.1.1. 白噪音</a></li>
<li><a href="#23312">2.3.3.1.2. 自相关序列</a></li>
</ul>
</li>
<li><a href="#2332-autocovariance">2.3.3.2. 自协方差函数 AutoCovariance</a></li>
<li><a href="#2333-acf">2.3.3.3. 自相关函数 ACF</a></li>
<li><a href="#2334-pacf">2.3.3.4. 偏自相关函数 PACF</a></li>
<li><a href="#2335-ljung-box">2.3.3.5. Ljung-box 检验（白噪音检测）</a></li>
</ul>
</li>
<li><a href="#234">2.3.4. 平稳性</a><ul>
<li><a href="#2341">2.3.4.1. 平稳性分类</a></li>
<li><a href="#2342">2.3.4.2. 定性判断平稳性</a><ul>
<li><a href="#23421">2.3.4.2.1. 时序图</a></li>
<li><a href="#23422">2.3.4.2.2. 自相关图/偏相关图</a></li>
</ul>
</li>
<li><a href="#2343">2.3.4.3. 定量判定平稳性</a><ul>
<li><a href="#23431-adf">2.3.4.3.1. ADF检验</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#235">2.3.5. 概念漂移</a><ul>
<li><a href="#2351">2.3.5.1. 分类</a></li>
<li><a href="#2352">2.3.5.2. 检测</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#24">2.4. 多变量序列的数学特征</a><ul>
<li><a href="#241">2.4.1. 多变量之间的相关性/独立性</a></li>
<li><a href="#242">2.4.2. 多变量之间的协整关系</a><ul>
<li><a href="#2421">2.4.2.1. 多个序列变量组合的规则</a></li>
<li><a href="#2422-engle-granger">2.4.2.2. Engle-Granger两步协整检验</a></li>
<li><a href="#2423-jj">2.4.2.3. JJ检验</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#3">3. 随机变量的数据处理</a><ul>
<li><a href="#31">3.1. 离群点检测</a><ul>
<li><a href="#311">3.1.1. 阈值判定</a><ul>
<li><a href="#3111">3.1.1.1. 平滑序列</a></li>
</ul>
</li>
<li><a href="#312">3.1.2. 模型判定</a></li>
</ul>
</li>
<li><a href="#32">3.2. 缺失值和离群值处理</a><ul>
<li><a href="#321">3.2.1. 模型分析</a></li>
</ul>
</li>
<li><a href="#33">3.3. 采样</a><ul>
<li><a href="#331">3.3.1. 过采样</a></li>
<li><a href="#332">3.3.2. 欠采样</a></li>
</ul>
</li>
<li><a href="#34-box-cox">3.4. Box-cox变换</a><ul>
<li><a href="#341-box-cox">3.4.1. 标准 Box-cox 变换</a></li>
<li><a href="#342-lmbda">3.4.2. 参数lmbda 确定</a></li>
<li><a href="#343-box-cox">3.4.3. Box-cox逆变换</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4">4. 随机变量序列的数据处理</a><ul>
<li><a href="#41">4.1. 序列线性运算</a><ul>
<li><a href="#411">4.1.1. 序列组合</a></li>
</ul>
</li>
<li><a href="#42">4.2. 序列差分运算</a></li>
<li><a href="#43-">4.3. 非平稳序列-&gt;平稳序列</a></li>
</ul>
</li>
<li><a href="#5">5. 时间序列数据的组成与分解</a><ul>
<li><a href="#51">5.1. 时间序列的组成</a><ul>
<li><a href="#511">5.1.1. 趋势</a></li>
<li><a href="#512">5.1.2. 周期性</a></li>
<li><a href="#513">5.1.3. 季节性</a></li>
<li><a href="#514">5.1.4. 不规则变化</a></li>
</ul>
</li>
<li><a href="#52">5.2. 时间序列的分解</a><ul>
<li><a href="#521">5.2.1. 基本步骤</a></li>
<li><a href="#522">5.2.2. 经典时间序列分解法</a><ul>
<li><a href="#5221">5.2.2.1. 原理</a></li>
<li><a href="#5222">5.2.2.2. 使用</a></li>
</ul>
</li>
<li><a href="#523-x11">5.2.3. X11分解法</a><ul>
<li><a href="#5231">5.2.3.1. 原理</a></li>
</ul>
</li>
<li><a href="#524-seats">5.2.4. SEATS分解</a><ul>
<li><a href="#5241">5.2.4.1. 原理</a></li>
</ul>
</li>
<li><a href="#525-stl">5.2.5. STL 分解法</a><ul>
<li><a href="#5251">5.2.5.1. 原理</a><ul>
<li><a href="#52511-lowess">5.2.5.1.1. LOWESS 回归</a></li>
</ul>
</li>
<li><a href="#5252">5.2.5.2. 特点</a></li>
<li><a href="#5253">5.2.5.3. 使用</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#53-emd">5.3. 经验模态分解(EMD)</a></li>
</ul>
</li>
<li><a href="#6">6. 时间序列预测</a><ul>
<li><a href="#61">6.1. 基本步骤</a></li>
<li><a href="#62">6.2. 任务分类</a><ul>
<li><a href="#621">6.2.1. 一元时序时间预测</a><ul>
<li><a href="#6211">6.2.1.1. 平稳性时序预测</a></li>
<li><a href="#6212">6.2.1.2. 差分时序数据结构</a></li>
</ul>
</li>
<li><a href="#622">6.2.2. 多元时序时间预测</a></li>
</ul>
</li>
<li><a href="#63">6.3. 前处理</a><ul>
<li><a href="#631">6.3.1. 频域</a></li>
<li><a href="#632">6.3.2. 时域处理</a><ul>
<li><a href="#6321">6.3.2.1. 异常检测</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#64">6.4. 模型评价与选择</a><ul>
<li><a href="#641-aicbic">6.4.1. 模型选择AIC与BIC：选择更简单的模型</a><ul>
<li><a href="#6411-armapq-p-q">6.4.1.1. 示例：ARMA(p,q) 模型中p q参数的确定</a></li>
</ul>
</li>
<li><a href="#642">6.4.2. 模型评估</a><ul>
<li><a href="#6421">6.4.2.1. 残差检验分析</a></li>
</ul>
</li>
<li><a href="#643">6.4.3. 过度拟合和参数冗余</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#7">7. 时间序列预测方法（模型）</a><ul>
<li><a href="#71">7.1. 平均注意力预测</a><ul>
<li><a href="#711-ma">7.1.1. 移动平均MA</a></li>
</ul>
</li>
<li><a href="#72">7.2. 近注意力</a><ul>
<li><a href="#721-naive">7.2.1. Naïve 方法</a></li>
<li><a href="#722">7.2.2. 指数平滑</a><ul>
<li><a href="#_1">权重移动平均</a></li>
</ul>
</li>
<li><a href="#723-ar">7.2.3. 自回归模型 AR</a></li>
<li><a href="#724-ma">7.2.4. 移动平均模型 MA</a></li>
<li><a href="#725-arma">7.2.5. 自回归移动平均模型 ARMA</a></li>
<li><a href="#726-arima">7.2.6. 差分自回归移动平均模型 ARIMA</a></li>
</ul>
</li>
<li><a href="#73">7.3. 选择注意力</a><ul>
<li><a href="#731">7.3.1. 漂移法（趋势法）</a></li>
<li><a href="#732">7.3.2. 马尔可夫链</a></li>
<li><a href="#733">7.3.3. 神经网络</a></li>
</ul>
</li>
<li><a href="#74">7.4. 预测区间</a></li>
</ul>
</li>
<li><a href="#9">9. 参考资料</a></li>
</ul>
</div>
<h1 id="1">1. 前言</h1>
<p>一说起时间序列大家并不会陌生。每时刻的甲醛浓度变化、每日股票闭盘价格、共享单车每日租车数等等都可以看做一系列时间点上的观测，在一系列时间点上观测获取的数据也就是我们俗称的时间序列数据。</p>
<h1 id="2">2. 随机变量的数学统计特征</h1>
<h2 id="21">2.1. 单变量的数学特征</h2>
<h3 id="211-">2.1.1. 期望--中心度</h3>
<p>对于连续型随机变量$X$，有概率密度函数$f(x)$,则定义<br />
$$E(X)= \int_{ - \infty }^{ + \infty } {f(x)dx} $$<br />
为$X$的数学期望。</p>
<p>对于离散型的随机变量$X$，$X$的数学期望就是随机变量$X$的取值与发生概率相乘得到的加和。</p>
<p>$$E(X)= \sum {f(x_i)} $$</p>
<h3 id="212-">2.1.2. 方差--分散度</h3>
<p>设$X$是一个随机变量，若 $E{[X-E(X)]^2}$存在，则称$E{[X-E(X)]}$为$X$的<strong>方差</strong>，记为$D(X)$或$Var(X)$，即<br />
$$D(X) = Var(x) = E{[X-E(X)]^2}$$</p>
<p>$\sqrt{D(X)}$称为$X$的标准差；</p>
<p>若$X$是离散型随机变量,则</p>
<p>$$D(X)= \sum_{k=1}^{\infty}[x_{k}-E(X)]^{2}p_{k}$$</p>
<p>若$X$是连续型随机变量，则</p>
<p>$$D(X)= \int_{-\infty}^{\infty}[x-E(X)]^{2}f(x)dx$$</p>
<p>补充：</p>
<blockquote>
<p>方差的推导关系：<br />
$\color{blue}{D(X) }$<br />
$= E{[X-E(X) ]^2 }$<br />
$= E{X^2-2XE(X)+[E(X) ]^2 }$<br />
$=E(X^2 )-2E(X)E(X)+[E(X) ]^2$<br />
$\color{blue}{=E(X^2 )-[E(X)]^2}$</p>
</blockquote>
<h2 id="22">2.2. 多变量的数学特征</h2>
<h3 id="221-">2.2.1. 协方差--关联方向协同性</h3>
<p>称$E{(X-E(X))(y-E(Y))}$为随机变量$X$与$Y$的协方差，记为$Cov(X,Y)$</p>
<p>$${Cov(X,Y)}<br />
=E{(X-E(X) )(y-E(Y))}<br />
{=E(XY)-E(X)E(Y)}$$</p>
<h3 id="222-">2.2.2. 相关系数--关联紧密性</h3>
<p>相关性（correlation）是两个随机变量和之间<strong>线性关系的强度</strong>和方向。</p>
<h4 id="2221">2.2.2.1. 皮尔逊相关系数</h4>
<p>Pearson product-moment correlation coefficient<br />
称<br />
$$ρ_{X,Y}=\frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}}$$</p>
<p>为随机变量$X$与$Y$的相关系数。描述X 与Y的关联度。相关系数就是消除了量纲的影响。</p>
<p><img alt="" src="../../../../attach/images/2019-10-18-09-16-31.png" /></p>
<h2 id="23">2.3. 单变量序列的数学特征</h2>
<p>类比于随机变量的数学特征，下面是随机变量序列的一些数学特征：</p>
<p>随机变量序列${y_{t}:t=0,1,2,... }$称为一个时间序列模型。</p>
<h3 id="231-">2.3.1. 均值函数--中心度</h3>
<p>$$u_{t}=E(y_{t} )，t=0,1,2,…$$</p>
<h3 id="232">2.3.2. 方差</h3>
<p><img alt="" src="../../../../attach/images/2019-10-19-16-52-43.png" /></p>
<h3 id="233">2.3.3. 自相关性</h3>
<p>序列相关（serial correlation），也叫自相关（autocorrelation），是指一个时间序列{x1,x2,x3...,xn}这些值前后自己相关，又称为滞后相关性。</p>
<h4 id="2331">2.3.3.1. 依据自相关性的序列分类</h4>
<div class="hlcode"><pre><span class="n">digraph</span> <span class="p">{</span>
    <span class="err">序列数据</span><span class="o">-&gt;</span><span class="err">自相关序列</span>
    <span class="err">序列数据</span><span class="o">-&gt;</span><span class="err">序列不相关序列（白噪音）</span>
<span class="p">}</span>
</pre></div>


<h6 id="23311">2.3.3.1.1. 白噪音</h6>
<p>白噪声序列的自相关函数为0（ρ0 =1除外）。</p>
<p><img alt="" src="../../../../attach/images/2019-10-19-17-22-18.png" /></p>
<p>实际应用中如果样本自相关函数近似为零（ACF 图中都位于控制线之内或基本不超出控制线），则可认为该序列是白噪声的样本。</p>
<p><img alt="" src="../../../../attach/images/2019-10-19-16-25-49.png" /></p>
<p>设 {Xt} 是独立同分布的二阶矩有限的随机变量，称 {Xt} 为<strong>独立同分布白噪声 (white noise)</strong>，又称为<strong>纯随机序列</strong>。最常用的白噪声一般假设均值为零。如果 {Xt} 独立同 N(0,σ2) 分布，称 {Xt} 为<strong>高斯 (Gaussian) 白噪声</strong>或正态白噪声。</p>
<h6 id="23312">2.3.3.1.2. 自相关序列</h6>
<p>判定序列的自相关性指标有：<br />
1. 自协方<br />
2. ACF<br />
3. PACF<br />
4. LB 检验</p>
<p>ACF还是PACF都仅仅考虑是否存在某一特定滞后阶数的相关。LB检验则是基于一系列滞后阶数，</p>
<h4 id="2332-autocovariance">2.3.3.2. 自协方差函数 AutoCovariance</h4>
<p>$$\color{red}{\gamma{(t,s)}}<br />
=Cov(y_t  ,y_s )<br />
=E[(y_t-u_t )(y_s-u_s ) ]<br />
\color{red}{=E(y_t y_s )-u_{t} u_{s}},<br />
t,s=0,1,2,…$$<br />
某个信号与其自身经过一定时间平移之后的相似性</p>
<h4 id="2333-acf">2.3.3.3. 自相关函数 ACF</h4>
<p>$$ρ_{k}=\frac{Cov(y_{t},y_{t-k})}{\sqrt{Var(y_{t-k})Var(y_t)}}$$</p>
<p>$k$ 滞后因子(置滞后项),就是做差分的 时差 <br />
$ρ_{k}$ 当滞后因子为k时的自相关系数<br />
$y_{t-k}$ 做差分后的序列</p>
<p>应为对于特定序列Y而言，自相关系数 是一个与 滞后因子k 相关的函数。将其称为自相关函数 ACF</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">statsmodels.tsa.api</span> <span class="kn">as</span> <span class="nn">smt</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">tsa是Time Series analysis缩写</span>
<span class="sd">tsa的stattools（统计工具）提供了计算acf和pacf以及后面要用到的adfuller单位根检验函数</span>
<span class="sd">使用help(smt.stattools.acf)可以查看相关参数设置</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c"># 计算自相关系数，这里设置滞后项为5期,默认是40期滞后</span>
<span class="n">acf</span><span class="o">=</span><span class="n">smt</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">acf</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">nlags</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="c"># 计算偏自相关系数</span>
<span class="n">pacf</span><span class="o">=</span><span class="n">smt</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">pacf</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">nlags</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">&#39;自相关系数为：{acf};</span><span class="se">\n</span><span class="s">偏自相关系数为：{pacf}&#39;</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span>
<span class="err">自相关系数为：</span><span class="p">[</span><span class="mf">1.</span> <span class="mf">0.99098764</span> <span class="mf">0.98189466</span> <span class="mf">0.97312885</span> <span class="mf">0.96252012</span> <span class="mf">0.95335064</span><span class="p">]</span>
<span class="err">偏自相关系数为：</span><span class="p">[</span> <span class="mf">1.</span> <span class="mf">0.99231072</span> <span class="o">-</span><span class="mf">0.01047826</span>  <span class="mf">0.01620047</span> <span class="o">-</span><span class="mf">0.12635305</span>  <span class="mf">0.09200772</span><span class="p">]</span>


<span class="kn">from</span> <span class="nn">statsmodels.graphics</span> <span class="kn">import</span> <span class="n">tsaplots</span>
<span class="n">tsapltots</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">Train_Y</span><span class="p">,</span><span class="n">use_vlines</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">lags</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;60 以后tsapltots判定为acf==0 (alpha=0.05,95%置信度)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<h4 id="2334-pacf">2.3.3.4. 偏自相关函数 PACF</h4>
<p>PACF</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">statsmodels.tsa.api</span> <span class="kn">as</span> <span class="nn">smt</span>

<span class="n">pacf</span><span class="o">=</span><span class="n">smt</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">pacf</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="n">nlags</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="c"># pacf .shape ==df.shape </span>

<span class="kn">from</span> <span class="nn">statsmodels.graphics</span> <span class="kn">import</span> <span class="n">tsaplots</span>
<span class="n">tsaplots</span><span class="o">.</span><span class="n">plot_pacf</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">ax</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">lags</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s">&#39;ywunbiased&#39;</span><span class="p">,</span>
    <span class="n">use_vlines</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s">&#39;Partial Autocorrelation&#39;</span><span class="p">,</span>
    <span class="n">zero</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">vlines_kwargs</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;60 以后tsapltots判定为acf==0 (alpha=0.05,95%置信度)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p>滞后相关的一种统计检验</p>
<h4 id="2335-ljung-box">2.3.3.5. Ljung-box 检验（白噪音检测）</h4>
<p>对于序列<br />
$$X_n={ x_1,x_2,...x_n  }$$</p>
<p>为了检验时间序列样本是否来自白噪声序列，可以检验 ρk =0,k =1,2,... 的零假设。<br />
Box 和 Pierce(Box and Pierce, 1970) 提出了混成统计量 (Portmanteau statistic)用来检验零假设H0。<br />
$$H0 : ρ1 =···= ρm =0$$</p>
<p>$$Ha : 不全为零$$</p>
<p>在{Xt}是独立白噪声序列条件下，Q∗(m) 近似服从 χ2(m) 分布。给定检验水平 α，当 Q∗(m) &gt; qchisq(1− α,m) 时拒绝 H0，否定白噪声假设。</p>
<p>Ljung 和 Box(Ljung and Box, 1978) 对此检验方法进行了改进。统计量改为<br />
$$Q(m)= T(T +2) \sum_{j=1}^m=\frac{ρ2}{T −j} $$</p>
<p>在独立同分布白噪声假设下仍近似服从 χ2(m) 分布。当 Q(m) &gt; qchisq(1−α,m) 时拒绝 H0，否定白噪 声假设。这个检验称为 Ljung-Box 白噪声检验。</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">statsmodels</span>
<span class="n">q_statarray</span><span class="p">,</span><span class="n">p_value</span> <span class="o">=</span><span class="n">statsmodels</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">q_stat</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nobs</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s">&#39;ljungbox&#39;</span><span class="p">)</span>

<span class="n">q_statarray</span>  <span class="c"># shape =x.shape</span>
<span class="o">&gt;&gt;&gt;</span>

<span class="n">p_value</span>  <span class="c"># shape =x.shape</span>
<span class="o">&gt;&gt;&gt;</span>

<span class="c"># p_valeue 一般查看最后一个值</span>
<span class="c"># 当 p_valeue &gt; 5%(0.05) ,则接收假设，认为序列是白噪音 </span>
<span class="c"># 当 p_valeue &lt;5% , 则拒绝假设，认为序列是非白噪音 </span>
</pre></div>


<h3 id="234">2.3.4. 平稳性</h3>
<p><strong>平稳性</strong>就是时间序列的统计性质关于时间平移的不变性，要求序列的均值和方差不发生明显变化。</p>
<h4 id="2341">2.3.4.1. 平稳性分类</h4>
<div class="hlcode"><pre><span class="n">digraph</span> <span class="p">{</span>
    <span class="err">序列数据</span><span class="o">-&gt;</span><span class="err">非平稳序列</span>
    <span class="err">序列数据</span><span class="o">-&gt;</span><span class="err">平稳序列</span>
    <span class="err">平稳序列</span><span class="o">-&gt;</span><span class="err">强平稳序列（理论上）</span>
    <span class="err">平稳序列</span><span class="o">-&gt;</span><span class="err">弱平稳序列</span><span class="p">[</span><span class="n">color</span><span class="o">=</span><span class="n">red</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s">&quot;一般指的是&quot;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>


<p><strong>严平稳</strong><br />
严平稳表示所用统计性质不随时间的改变而改变。</p>
<p>$$F(x_1,x_2..x_n)=F(x_{1+t},x_{2+t}...,x_{n+t})$$<br />
F为{x1,x2,...xn}的联合分布。过于严苛，一般实际中都是弱平稳序列。一般提及稳定序列指的是弱平稳序列。 <br />
<strong>弱平稳</strong><br />
弱平稳：期望与相关系数（依赖性）不变未来某时刻的$t$的值$Y_{t}$就要依赖于它的过去信息，所以需要依赖性</p>
<ol>
<li>
<p>均值$E(Y_{t})= μ$与时间$t$无关的常数；</p>
</li>
<li>
<p>方差$Var(Y_{t} )= \gamma$与时间$t$无关的常数；</p>
</li>
<li>
<p>协方差$Cov(Y_{t},Y_{t+k} )= \gamma_{0,k}$只与时间间隔$k$有关，与时间$t$无关的常数。</p>
</li>
<li>
<p>自相关系数$ρ_{k }=\frac{Cov(y_{t },   y_{t-k})}{\sqrt{Var(y_{t-k)}Var{(y_t)}}}=\frac{Cov(y_{t },   y_{t-k})}{Var{(y_t)}}= \frac{\gamma_{k}}{\gamma_{0}} $</p>
</li>
</ol>
<h4 id="2342">2.3.4.2. 定性判断平稳性</h4>
<h5 id="23421">2.3.4.2.1. 时序图</h5>
<p>平稳序列：在一定范围内上下波动<br />
非平稳序列：有上升、下降趋势 </p>
<p><img alt="" src="../../../../attach/images/2019-10-19-16-10-58.png" /></p>
<h5 id="23422">2.3.4.2.2. 自相关图/偏相关图</h5>
<p>平稳序列: 自相关系数快速（或某一阶段后）降低为0（或附近）<br />
非平稳序列: 自相关系数缓慢降低</p>
<h4 id="2343">2.3.4.3. 定量判定平稳性</h4>
<h5 id="23431-adf">2.3.4.3.1. ADF检验</h5>
<p>ADF检验全称是 Augmented Dickey-Fuller test，也叫做单位根（unit root）检验。顾名思义，ADF是 Dickey-Fuller检验的增广形式。DF检验只能应用于一阶情况，当序列存在高阶的滞后相关时，可以使用ADF检验，所以说ADF是对DF检验的扩展。<br />
<strong>单位根</strong>就是指单位根过程，可以证明，序列中存在单位根过程就不平稳，会使回归分析中存在伪回归</p>
<p>主要思想：</p>
<div class="hlcode"><pre><span class="n">digraph</span> <span class="n">a</span><span class="p">{</span>
    <span class="err">假设存在单位根</span><span class="o">-&gt;</span><span class="err">平稳序列</span><span class="p">[</span><span class="n">label</span><span class="o">=</span><span class="s">&quot;不存在 p_value&lt;0.05&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">blue</span><span class="p">]</span>
    <span class="err">假设存在单位根</span><span class="o">-&gt;</span><span class="err">非平稳序列</span><span class="p">[</span><span class="n">label</span><span class="o">=</span><span class="s">&quot;存在 p_value&gt;0.05&quot;</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="n">red</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>


<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">arch.unitroot</span> <span class="kn">import</span> <span class="n">ADF</span>

<span class="n">ADF_instance</span><span class="o">=</span><span class="n">ADF</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">lags</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="k">print</span> <span class="p">(</span><span class="n">ADF_instance</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
   <span class="n">Augmented</span> <span class="n">Dickey</span><span class="o">-</span><span class="n">Fuller</span> <span class="n">Results</span>   
<span class="o">=====================================</span>
<span class="n">Test</span> <span class="n">Statistic</span>                 <span class="o">-</span><span class="mf">8.635</span>
<span class="n">P</span><span class="o">-</span><span class="n">value</span>                         <span class="mf">0.000</span>
<span class="n">Lags</span>                               <span class="mi">10</span>
<span class="o">-------------------------------------</span>

<span class="n">Trend</span><span class="p">:</span> <span class="n">Constant</span>
<span class="n">Critical</span> <span class="n">Values</span><span class="p">:</span> <span class="o">-</span><span class="mf">3.43</span> <span class="p">(</span><span class="mi">1</span><span class="o">%</span><span class="p">),</span> <span class="o">-</span><span class="mf">2.86</span> <span class="p">(</span><span class="mi">5</span><span class="o">%</span><span class="p">),</span> <span class="o">-</span><span class="mf">2.57</span> <span class="p">(</span><span class="mi">10</span><span class="o">%</span><span class="p">)</span>
<span class="n">Null</span> <span class="n">Hypothesis</span><span class="p">:</span> <span class="n">The</span> <span class="n">process</span> <span class="n">contains</span> <span class="n">a</span> <span class="n">unit</span> <span class="n">root</span><span class="o">.</span>
<span class="n">Alternative</span> <span class="n">Hypothesis</span><span class="p">:</span> <span class="n">The</span> <span class="n">process</span> <span class="ow">is</span> <span class="n">weakly</span> <span class="n">stationary</span><span class="o">.</span>

<span class="c"># 若按照5% 致信区间判定</span>

<span class="k">if</span> <span class="n">ADF_instance</span><span class="o">.</span><span class="n">stat</span><span class="o">&lt;</span><span class="n">ADF_instance</span><span class="o">.</span><span class="n">critical_values</span><span class="p">[</span><span class="s">&quot;5%&quot;</span><span class="p">]:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;拒绝假设，不存在单元根，序列是宽平稳的，是平稳序列&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">ADF_instance</span><span class="o">.</span><span class="n">p_value</span><span class="o">&lt;</span><span class="mf">0.05</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;拒绝假设，不存在单元根，序列是宽平稳的，是平稳序列&quot;</span><span class="p">)</span>
</pre></div>


<h3 id="235">2.3.5. 概念漂移</h3>
<p>概念漂移（Concept drift）就是<strong>目标变量随着时间的推移发生改变</strong>。概念指的就是一个模型要去预测的一个目标变量</p>
<p><img alt="" src="../../../../attach/images/2019-10-21-11-56-05.png" /></p>
<h4 id="2351">2.3.5.1. 分类</h4>
<ul>
<li>
<p>sudden 指的是迅速同时又不可逆的改变，强调的是发生的迅速。</p>
</li>
<li>
<p>incremental和gradual都是强调改变发生的缓慢，incremental强调值的随时间改变，gradual则是数据分布的改变。也有些研究者将这两种变化划分为同一类，用incremental gradual这个术语来代替。</p>
</li>
<li>
<p>recurring则是一种temporary（临时性）的改变，在一段短时间内会恢复之前的状态。所以也有些研究者将其称为local drift，它不具有周期性，是在不规则的时间间隔内反复转换。</p>
</li>
<li>
<p>blip是代表一种很稀少的事件，它可以被视为一种anomaly或者outlier（异常）。</p>
</li>
<li>
<p>noise是一种随机的改变，通常这种数据会从样本数据中filter out。</p>
</li>
</ul>
<h4 id="2352">2.3.5.2. 检测</h4>
<p>DDM（Drift Detection Method）</p>
<p>EDDM（Early Drift Detection Method）</p>
<p>DDD（Diversity for Dealing with Drifts）  </p>
<p>Ensemble with different diversity</p>
<p>Hoeffding trees</p>
<p>Ensemble Learnings</p>
<h2 id="24">2.4. 多变量序列的数学特征</h2>
<h3 id="241">2.4.1. 多变量之间的相关性/独立性</h3>
<p>相关关系（correlation）</p>
<div class="hlcode"><pre><span class="n">stattools</span><span class="o">.</span><span class="n">ccovf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[,</span> <span class="n">adjusted</span><span class="p">,</span> <span class="n">demean</span><span class="p">])</span>

<span class="n">Calculate</span> <span class="n">the</span> <span class="n">crosscovariance</span> <span class="n">between</span> <span class="n">two</span> <span class="n">series</span><span class="o">.</span>

<span class="n">stattools</span><span class="o">.</span><span class="n">ccf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">[,</span> <span class="n">adjusted</span><span class="p">])</span>

<span class="n">The</span> <span class="n">cross</span><span class="o">-</span><span class="n">correlation</span> <span class="n">function</span><span class="o">.</span>
</pre></div>


<h3 id="242">2.4.2. 多变量之间的协整关系</h3>
<p>如果两组序列是非平稳的，但它们的线性组合可以得到一个平稳序列，那么我们就说这两组时间序列数据具有协整(cointegration)的性质。</p>
<h4 id="2421">2.4.2.1. 多个序列变量组合的规则</h4>
<p><img alt="" src="../../../../attach/images/2019-10-31-10-12-02.png" /></p>
<h4 id="2422-engle-granger">2.4.2.2. Engle-Granger两步协整检验</h4>
<p>若$Y_t$,$X_t$ 属于I(1) <br />
<strong>步骤</strong><br />
1. 通过最小二乘回归得到协整系数$\beta$和残差序列$R_t$<br />
   $Y_t=\beta X_t+R_t$<br />
2. 对残差序列$R_t$ 进行自稳定性检验（ADF），如果$R_t$ 平稳则协整</p>
<p><strong>缺点</strong> </p>
<p>不能同时处理多个协整关系</p>
<p>原假设H0是不存在协整关系，替代假设是存在协整关系。如果p值很小，低于临界大小，那么我们可以拒绝没有协整关系的假设，认为存在协整关系。</p>
<div class="hlcode"><pre><span class="c">#cointegration 协整性</span>
<span class="n">coint_t</span><span class="p">,</span><span class="n">p_value</span><span class="p">,</span><span class="n">crit_value</span><span class="o">=</span><span class="n">statsmodels</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">coint</span><span class="p">(</span><span class="n">y0</span><span class="p">,</span><span class="n">y1</span><span class="p">,</span><span class="n">trend</span> <span class="o">=</span><span class="s">&#39;c&#39;</span><span class="p">,</span><span class="n">method</span> <span class="o">=</span><span class="s">&#39;aeg&#39;</span><span class="p">,</span><span class="n">maxlag</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span><span class="n">autolag</span> <span class="o">=</span><span class="s">&#39;aic&#39;</span><span class="p">,</span><span class="n">return_results</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span>

<span class="k">if</span> <span class="n">p_value</span><span class="o">&lt;</span><span class="mf">0.01</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;y0 y1 存在协整关系&quot;</span><span class="p">)</span>
<span class="n">y0</span><span class="p">:</span>
</pre></div>


<p><strong>应用</strong></p>
<p>两组时间序列数据的差是平稳的<br />
当两只股票的价差过大，根据平稳性我们预期价差会收敛，因此买入低价的股票，卖空高价的股票，等待价格回归的时候进行反向操作从而获利。<br />
这就是配对交易（pairs trading）的由来。</p>
<p>(Phillips and Ouliaris 1990)给出了利用回归残差进行协整检验的方法， 包含两种方法， 方差比方法和多元迹统计量方法。 R扩展包urca的ca.po()可以用来计算Phillips-Ouliaris检验。 选项demean="constant"指定有确定性常数趋势， demean="trend"指定有确定性线性趋势， 缺省为demean="none"，没有确定性趋势（无漂移）。 选项type="Pu"指定使用方差比方法， 选项type="Pz"指定使用多元迹方法， 多元迹方法对哪个分量作为回归因变量不敏感。</p>
<h4 id="2423-jj">2.4.2.3. JJ检验</h4>
<p>而Johansen协整检验法采用的是多元方程技术</p>
<div class="hlcode"><pre><span class="n">statsmodels</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">vector_ar</span><span class="o">.</span><span class="n">vecm</span><span class="o">.</span><span class="n">coint_johansen</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">det_order</span><span class="p">,</span> <span class="n">k_ar_diff</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">coint_johansen</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">det_order</span><span class="p">,</span> <span class="n">k_ar_diff</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Johansen 检验</span>

<span class="sd">    参数</span>
<span class="sd">    ----------</span>
<span class="sd">    endog : array_like (nobs_tot x neqs)</span>
<span class="sd">        Data to test</span>
<span class="sd">    det_order : int</span>
<span class="sd">        * -1 - no deterministic terms</span>
<span class="sd">        * 0 - constant term</span>
<span class="sd">        * 1 - linear trend</span>
<span class="sd">    k_ar_diff : int, nonnegative</span>
<span class="sd">        Number of lagged differences in the model.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : JohansenTestResult</span>
<span class="sd">        An object containing the test&#39;s results. The most important attributes</span>
<span class="sd">        of the result class are:</span>

<span class="sd">        * trace_stat and trace_stat_crit_vals</span>
<span class="sd">        * max_eig_stat and max_eig_stat_crit_vals</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">warnings</span>
    <span class="k">if</span> <span class="n">det_order</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;Critical values are only available for a det_order of &quot;</span>
                      <span class="s">&quot;-1, 0, or 1.&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">HypothesisTestWarning</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">endog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">12</span><span class="p">:</span>  <span class="c"># todo: test with a time series of 13 variables</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s">&quot;Critical values are only available for time series &quot;</span>
                      <span class="s">&quot;with 12 variables at most.&quot;</span><span class="p">,</span>
                      <span class="n">category</span><span class="o">=</span><span class="n">HypothesisTestWarning</span><span class="p">)</span>

    <span class="kn">from</span> <span class="nn">statsmodels.regression.linear_model</span> <span class="kn">import</span> <span class="n">OLS</span>

    <span class="k">def</span> <span class="nf">detrend</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">order</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">order</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span>
        <span class="k">return</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)),</span>
                                <span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span><span class="o">.</span><span class="n">resid</span>

    <span class="k">def</span> <span class="nf">resid</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="n">endog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">endog</span><span class="p">)</span>
    <span class="n">nobs</span><span class="p">,</span> <span class="n">neqs</span> <span class="o">=</span> <span class="n">endog</span><span class="o">.</span><span class="n">shape</span>

    <span class="c"># why this?  f is detrend transformed series, det_order is detrend data</span>
    <span class="k">if</span> <span class="n">det_order</span> <span class="o">&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">det_order</span>

    <span class="n">endog</span> <span class="o">=</span> <span class="n">detrend</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">det_order</span><span class="p">)</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">lagmat</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">k_ar_diff</span><span class="p">)</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="n">k_ar_diff</span><span class="p">:]</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">detrend</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="n">dx</span> <span class="o">=</span> <span class="n">dx</span><span class="p">[</span><span class="n">k_ar_diff</span><span class="p">:]</span>

    <span class="n">dx</span> <span class="o">=</span> <span class="n">detrend</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">r0t</span> <span class="o">=</span> <span class="n">resid</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
    <span class="c"># GH 5731, [:-0] does not work, need [:t-0]</span>
    <span class="n">lx</span> <span class="o">=</span> <span class="n">endog</span><span class="p">[:(</span><span class="n">endog</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">k_ar_diff</span><span class="p">)]</span>
    <span class="n">lx</span> <span class="o">=</span> <span class="n">lx</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">dx</span> <span class="o">=</span> <span class="n">detrend</span><span class="p">(</span><span class="n">lx</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">rkt</span> <span class="o">=</span> <span class="n">resid</span><span class="p">(</span><span class="n">dx</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>  <span class="c"># level on lagged diffs</span>
    <span class="c"># Level covariance after filtering k_ar_diff</span>
    <span class="n">skk</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rkt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">rkt</span><span class="p">)</span> <span class="o">/</span> <span class="n">rkt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c"># Covariacne between filtered and unfiltered</span>
    <span class="n">sk0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">rkt</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">r0t</span><span class="p">)</span> <span class="o">/</span> <span class="n">rkt</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">s00</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r0t</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">r0t</span><span class="p">)</span> <span class="o">/</span> <span class="n">r0t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">sk0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inv</span><span class="p">(</span><span class="n">s00</span><span class="p">),</span> <span class="n">sk0</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">skk</span><span class="p">)</span>
    <span class="n">au</span><span class="p">,</span> <span class="n">du</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">sig</span><span class="p">))</span>  <span class="c"># au is eval, du is evec</span>

    <span class="n">temp</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">du</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">skk</span><span class="p">,</span> <span class="n">du</span><span class="p">))))</span>
    <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">du</span><span class="p">,</span> <span class="n">temp</span><span class="p">)</span>

    <span class="c"># JP: the next part can be done much  easier</span>
    <span class="n">auind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">au</span><span class="p">)</span>
    <span class="n">aind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">auind</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">au</span><span class="p">[</span><span class="n">aind</span><span class="p">]</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">dt</span><span class="p">[:,</span> <span class="n">aind</span><span class="p">]</span>
    <span class="c"># Normalize by first non-zero element of d, usually [0, 0]</span>
    <span class="c"># GH 5517</span>
    <span class="n">non_zero_d</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">flat</span> <span class="o">!=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">non_zero_d</span><span class="p">):</span>
        <span class="n">d</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">flat</span><span class="p">[</span><span class="n">non_zero_d</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="c">#  Compute the trace and max eigenvalue statistics</span>
    <span class="n">lr1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">neqs</span><span class="p">)</span>
    <span class="n">lr2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">neqs</span><span class="p">)</span>
    <span class="n">cvm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">neqs</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">cvt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">neqs</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">iota</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">neqs</span><span class="p">)</span>
    <span class="n">t</span><span class="p">,</span> <span class="n">junk</span> <span class="o">=</span> <span class="n">rkt</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">neqs</span><span class="p">):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">iota</span> <span class="o">-</span> <span class="n">a</span><span class="p">)[</span><span class="n">i</span><span class="p">:]</span>
        <span class="n">lr1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">lr2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">t</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">cvm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c_sja</span><span class="p">(</span><span class="n">neqs</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">det_order</span><span class="p">)</span>
        <span class="n">cvt</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">c_sjt</span><span class="p">(</span><span class="n">neqs</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">det_order</span><span class="p">)</span>
        <span class="n">aind</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">return</span> <span class="n">JohansenTestResult</span><span class="p">(</span><span class="n">rkt</span><span class="p">,</span> <span class="n">r0t</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">lr1</span><span class="p">,</span> <span class="n">lr2</span><span class="p">,</span> <span class="n">cvt</span><span class="p">,</span> <span class="n">cvm</span><span class="p">,</span> <span class="n">aind</span><span class="p">)</span>
</pre></div>


<h1 id="3">3. 随机变量的数据处理</h1>
<h2 id="31">3.1. 离群点检测</h2>
<p>外部干扰作用于系统的开始 ，并且其作用方式与系统的动态模型有关 ；第三种是水<br />
平移位离群点（level shift outlier） ，造成这种离群点的干扰是在某一时刻 T ，系统<br />
的结构发生了变化 ，并持续影响 T 时刻以后的所有行为 ，在数列上往往表现出 T<br />
时刻前后的序列均值发生水平位移 ；第四种是暂时变更离群点（tempo rary change<br />
outlier） ，造成这种离群点的干扰是在 T 时刻干扰发生时具有一定初始效应 ，以后<br />
随时间根据衰减因子 δ的大小呈指数衰减的一类干扰事件 。</p>
<p>显然 ，在得到时间序列以后 ，首先要检验是否存在离群点 ，如果存在的话 ，还需<br />
要进一步判明在何时出现了离群点 ，以及所出现的离群点属于何种类型 。 </p>
<p>检验离群点并对其进行处理的方法很多 ，但归纳起来大致有两类 </p>
<h3 id="311">3.1.1. 阈值判定</h3>
<p>某一时刻的数值超出了一定的范围 ，则认为该点是一个离群点 ，并用一<br />
定的方法进行剔点（剔除离群点）处理。</p>
<h4 id="3111">3.1.1.1. 平滑序列</h4>
<p>假定正常的序列值是平滑的 ，而离群点是突变的，检测其是否显著地大（或小）</p>
<p>种方法是检测序列值与其相应的曲线平滑估计值的绝对离差是否大于某一预先设定值 k</p>
<h3 id="312">3.1.2. 模型判定</h3>
<h2 id="32">3.2. 缺失值和离群值处理</h2>
<p>离群值和缺失值已经用估计值进行替换。</p>
<p>缺失值可能会带来很多麻烦，所有有必要在对时间序列建模之前，分析一下缺失值是否会给预测带来偏差。例如，假设我们正在研究商店的销售额数据，当商店关闭时，在公共假期时就会出现缺失值，也就是当天的销售额为0。假期后的第二天会突然增加销售额。如果我们在预测模型中没有考虑到这一点，则会给模型带来预测偏差。解决这种情况的一种方法是使用动态回归模型（dynamic regression model），该模型具有虚拟变量（dummy variables），指示某一天是公共假日还是非公共假日。注意处理这样的缺失值没有自动化的方法，因为它们依赖于特定的预测上下文。对于缺失值的处理需要根据预测的具体场景有很多处理方法（比如截取最后一个缺失值后面的时间序列进行分析、让模型对缺失值产生估计来当做本来缺失的观测值），这里不展开详细讲解。</p>
<p>异常值是与时间序列中的大多数观测值非常不同的观测值。它们可能是错误的，如果数据中存在极端异常值，那么可能会导致预测方法不能很好地工作。</p>
<p>在这种情况下，我们需要有一些手段来处理异常值，比如用缺失值或与估计值来替换它们，视具体场景而定。但是如果简单地替换异常值而不考虑它们发生的原因是一种危险的做法。因为这些异常值可以提供关于产生异常数据的过程的一些有用信息，而这些信息在预测时应该被考虑到。</p>
<p>具体在实际应用中，时间序列的初步分析可能需要考虑更多的方面，这里仅做科普，仅列举了几种操作，目的是让读者脑海中有一个印象初步分析需要做哪些工作。</p>
<p>到这初步分析已经做完，那么接下来应该就是选择模型了，那时间序列预测分析有哪些模型呢？它们有怎样的使用条件呢？在介绍预测模型之前，你得先了解一些基本的预测方法，这些方法是在预测模型中的基础也是核心关键</p>
<h4 id="321">3.2.1. 模型分析</h4>
<p>另一类是对数据进行模型分析 ，然后根据拟合模型后的剩余序列计算特定的统计量 ，测出显著的离群点及其类型 ，并用相应的模型进行修正 ，然后再对修正模型的剩余序列重复上述程序 ，依次测出各个离群点 。 </p>
<p>STL 分解<br />
STL 表示基于损失的季节性分解的过程。该技术能够将时间序列信号分解为三个部分：季节性变化（seasonal）、趋势变化（trend）和剩余部分（residue）。</p>
<h2 id="33">3.3. 采样</h2>
<h3 id="331">3.3.1. 过采样</h3>
<p>增加时间频率，插值 NAN</p>
<h3 id="332">3.3.2. 欠采样</h3>
<p>以一定时间间隔采样，MA  最好符合 周期 </p>
<h2 id="34-box-cox">3.4. Box-cox变换</h2>
<h3 id="341-box-cox">3.4.1. 标准 Box-cox 变换</h3>
<p>$$w_t =<br />
\begin{cases}<br />
\frac{x_t^\lambda-1}{\lambda}&amp; \lambda!=0\<br />
\ln{x_t}&amp; \lambda==0<br />
\end{cases}$$</p>
<p><strong>box1p</strong><br />
$$w_t =<br />
\begin{cases}<br />
\frac{(x_t+1)^\lambda-1}{\lambda}&amp; \lambda!=0\<br />
\ln{(x_t+1)}&amp; \lambda==0<br />
\end{cases}$$</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="n">x_norm</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">boxcox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">lmbda</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>


<h3 id="342-lmbda">3.4.2. 参数<code>lmbda</code> 确定</h3>
<p>参数<code>lmbda</code> 确定 总体上依据参数估计的方法进行，<br />
1. 最大释然估计(log-likelihood function,llf)<br />
Box-cox 变换 中参数<code>lmbda</code> $\lambda$的确定方法<br />
$$llf=(\lambda-1)\sum_i(\log{(x_i)})-\frac{N}{2}log(\frac{\sum_i(y_i-y)^2}{N})$$</p>
<p>其中Y是X的Box-cox 变换后的序列</p>
<div class="hlcode"><pre><span class="n">x_norm</span><span class="p">,</span> <span class="n">maxlog</span><span class="p">,</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">boxcox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">lmbda</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="c"># alpha: 执行区间因子0.90，90%</span>
<span class="c"># lmbda:  Box-cox</span>
<span class="c"># maxlog: log似然函数的最大值 </span>
<span class="n">maxlog</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="mf">0.69</span>

<span class="n">x_norm</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">boxcox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">lmbda</span><span class="o">=</span><span class="n">maxlog</span><span class="p">)</span>
</pre></div>


<p><img alt="" src="../../../../attach/images/2019-10-21-09-55-57.png" /></p>
<p>依据上图 确定 maxlog=4.08</p>
<ol>
<li>依据最大皮尔森相关系数估计</li>
</ol>
<p>如果X符合正态分布，则y = boxcox(x,lmbda)，求得到最大化np.corr(y,x)时候的lmbda</p>
<div class="hlcode"><pre><span class="n">maxlog</span><span class="o">=</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">boxcox_normmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s">&quot;pearsonr&quot;</span><span class="p">)</span>
</pre></div>


<h3 id="343-box-cox">3.4.3. Box-cox逆变换</h3>
<p>$$x_t =<br />
\begin{cases}<br />
e^{w_t}&amp; \lambda==0\<br />
(\lambda w_t +1)^{\frac{1}{\lambda}} &amp; \lambda!=0<br />
\end{cases}$$</p>
<div class="hlcode"><pre><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">inv_boxcox</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">lmbda</span><span class="p">)</span>
</pre></div>


<p>Box-cox 逆变换  处理数据偏执 <br />
$$x_t =<br />
\begin{cases}<br />
e^{w_t}<em>[1+\frac{\sigma^2_h}{2}]&amp; \lambda==0\<br />
(\lambda w_t +1)^{\frac{1}{\lambda}} </em>[1+\frac{\sigma^2_h(1-\lambda)}{2(\lambda w_t+1)^2}]&amp; \lambda!=0<br />
\end{cases}$$</p>
<div class="hlcode"><pre><span class="c">##没有现成的，只能自己写 </span>

<span class="c">#Function</span>
<span class="k">def</span> <span class="nf">invboxcox</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ld</span><span class="p">):</span>
   <span class="k">if</span> <span class="n">ld</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
   <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ld</span><span class="o">*</span><span class="n">y</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">ld</span><span class="p">))</span>

<span class="c"># Test the code</span>
<span class="n">x</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">]</span>
<span class="n">ld</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">boxcox</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">ld</span><span class="p">)</span>
<span class="k">print</span> <span class="n">invboxcox</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">ld</span><span class="p">)</span>
</pre></div>


<p><img alt="" src="../../../../attach/images/2019-10-19-13-19-26.png" /></p>
<h1 id="4">4. 随机变量序列的数据处理</h1>
<h2 id="41">4.1. 序列线性运算</h2>
<h3 id="411">4.1.1. 序列组合</h3>
<p>时间序列X_n<br />
$$ X_n={x_1,x_2..,x_n}$$<br />
时间序列Y_n<br />
$$ Y_n={y_1,y_2..,y_n}$$<br />
时间序列Z_n</p>
<p>$$ Z_n= {aX+bY+c} $$</p>
<p>类似的减法、乘法（log变换后）、除法（log变换后）都可以进行序列组合</p>
<h2 id="42">4.2. 序列差分运算</h2>
<p>时间序列<br />
$$ X_n={x_1,x_2..,x_n}$$</p>
<p>一阶差分<br />
$$  Y_{n-1}=\Delta^1 X_n={x_2-x_1,x_3-x_2..,x_n-x_{n-1}} ={y_1,y_2..,y_{n-1}}$$</p>
<p>二阶差分<br />
$$Z_{n-2}=\Delta^2 X= \Delta^1 Y={y_2-y_1,y_3-y_2..,y_{n-1}-y_{n-2}} ={z_1,z_2..,z_{n-2}}$$</p>
<p>p阶/高阶差分<br />
$$\Delta^p X=\Delta \Delta^{p-1}X$$</p>
<p>s步差分</p>
<p>$$\Delta_s X_n=X_n-X_{n+s}={x_1,x_2..,x_n}-{x_{1+s},x_{2+s}..,x_{n+s}}$$</p>
<p>联合p阶差分和s步差分</p>
<p>$$\Delta_s^p X_n$$</p>
<p><strong>实践</strong></p>
<div class="hlcode"><pre><span class="c"># 1阶1步差分</span>
<span class="c"># periods 步长</span>
<span class="n">df</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pd_series</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np_series</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c"># 1阶2步差分</span>
<span class="n">df</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pd_series</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c">##2阶1步差分</span>
<span class="n">pd_series</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">np_series</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p>差分的作用</p>
<p>对于不平稳的时间序列，我们一般会使用差分的方法得到想要的平稳序列，下图是美国消费者信心指数序列，一阶差分和二阶差分后的序列。</p>
<p>$\color{red}{如：下图中最上面的蓝色图像是原始数据，绿色图像一阶差分后的数据，红色图像是二阶差分后的数据，从差分效果来看，实现了平稳的基本需求。}$<br />
<img alt="这里写图片描述" src="http://img.blog.csdn.net/20171023100523600?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQva2ljaWxvdmU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" /></p>
<h2 id="43-">4.3. 非平稳序列-&gt;平稳序列</h2>
<p>我们要将时间序列转为平稳序列，有如下几种方法：</p>
<ol>
<li>取对数（Logarithmic）</li>
<li>差分（Difference）<br />
   a. 一阶差分 （First Difference）<br />
   b. 季节性差分（Seasonal Difference）</li>
<li>季节性调整 （Seasonal Adjustment）</li>
<li>时间序列分解 EMD 分解 </li>
</ol>
<p>季节调整是从原始时间序列中剔除季节性影响以分离出趋势、循环、季节、不规则</p>
<p>主流季节调整方法(即X-12-ARIMA和TRAMO/SEATS)</p>
<h1 id="5">5. 时间序列数据的组成与分解</h1>
<h2 id="51">5.1. 时间序列的组成</h2>
<p><strong>时间序列主要由以下4部分组成：</strong></p>
<ol>
<li>
<p>长期趋势Trend：现象在较长时期内受某种根本性因素作用而形成的总的变动趋势；</p>
</li>
<li>
<p>循环变动\周期性Cyclic：现象以若干年为周期(<strong>不固定频率</strong>)所呈现出的波浪起伏形态的有规律的变动；</p>
</li>
<li>
<p>季节性变化Seasonal variation：现象随着季节(<strong>已知并且固定的频率</strong>)的变化而发生的有规律的周期性变动；</p>
</li>
<li>
<p>不规则变化Irregular movement：是一种无规律可循的变动，包括严格的随机变动和不规则的突发性影响很大的变动两种类型。</p>
</li>
</ol>
<p><strong>时间序列成分的数学表达</strong></p>
<ol>
<li>加法<br />
假设一条时间序列是由多种成分相加得来，那么它可以写为如下形式：</li>
</ol>
<p>$$y_t=T_t+C_T+S_t+R_t$$</p>
<p>在上式中：趋势项T_t 、季节项S_t、周期项C_T、残差项R_t</p>
<p>如果<strong>季节性波动S_t</strong>的幅度或者<strong>趋势T_t、周期项C_t</strong>的波动不随时间序列水平的变化而变化，那么加法模型是最为合适的。<br />
2. 乘法表示 <br />
此外，时间序列也可以写成相乘的形式：</p>
<p>$$y_t=T_t<em>C_T</em>S_t*R_t = log{T_t}+log{C_t}+log{S_t}+log{R_t}$$</p>
<p>当<strong>季节项S_t或趋势周期项T_t /C_t的变化与时间序列的水平成比例</strong>时，则乘法模型更为合适。</p>
<p>在经济时间序列中，乘法模型较为常用。</p>
<h3 id="511">5.1.1. 趋势</h3>
<p>当一个时间序列数据长期增长或者长期下降时，表示该序列有趋势 。<br />
<img alt="" src="../../../../attach/images/2019-10-18-18-31-56.png" /><br />
<strong>趋势强度</strong>定义<br />
$$F_{T_t}=\max(0,1-\frac{Var(R_t)}{Var(T_t+R_t)})$$</p>
<p>F_Tt接近0时表示该序列几乎没有趋势性</p>
<h3 id="512">5.1.2. 周期性</h3>
<p>现象以若干年为周期(不固定频率)所呈现出的波浪起伏形态的有规律的变动；<br />
<img alt="" src="../../../../attach/images/2019-10-18-18-42-13.png" /></p>
<p>一般而言，周期的长度较长，并且周期的波动幅度也更大。</p>
<h3 id="513">5.1.3. 季节性</h3>
<p>季节性总是一个已知并且固定的频率。由于抗糖尿病药物的成本在年底时会有变化，导致上述抗糖尿药物的月销售额存在季节性。<br />
<img alt="" src="../../../../attach/images/2019-10-18-18-38-22.png" /><br />
<strong>季节性强度</strong>定义 <br />
$$F_{S_t}=\max(0,1-\frac{Var(R_t)}{Var(S_t+R_t)})$$<br />
F_St接近0时表示该序列几乎没有季节性</p>
<p>当季节模式明显时，ACF 图中季节窗口的整数倍处会反复出现特定的尖峰。<br />
<img alt="" src="../../../../attach/images/2019-11-30-17-51-15.png" /></p>
<p>一般的时间频率有以下值可供选择。</p>
<table>
<thead>
<tr>
<th>数据类型</th>
<th>频率</th>
</tr>
</thead>
<tbody>
<tr>
<td>年度</td>
<td>1</td>
</tr>
<tr>
<td>季度</td>
<td>4</td>
</tr>
<tr>
<td>月度</td>
<td>12</td>
</tr>
<tr>
<td>周</td>
<td>52</td>
</tr>
</tbody>
</table>
<p>实际上，一年并不是精准的52周。由于每四年是一个闰年，平均来看每年有 365.25/7 = 52.18 周。但大多数使用ts对象的函数都需要频率为整数。</p>
<p>如果观测频率大于每周一次，可以采用多种方法来处理频率。例如，日观测数据可能具有周季节性（frequency=7）或者具有年度季节性（frequency=365.25）。类似地，一个每分钟观测一次的数据可能具有时季节性（frequency=60），可能是日季节性（frequency=24x60=1440），还可能是周季节性（frequency=24x60x7=10080），甚至可能具有年度周期性（frequency=24x60x365.25=525960）。在我们处理时间序列之前，确定其频率至关重要。</p>
<h3 id="514">5.1.4. 不规则变化</h3>
<h2 id="52">5.2. 时间序列的分解</h2>
<h3 id="521">5.2.1. 基本步骤</h3>
<p><img alt="" src="../../../../attach/images/2019-10-18-15-23-12.png" /></p>
<ol>
<li>确定数据周期。</li>
<li>根据业务性质对数据周期进行判定</li>
<li>
<p>如果对数据周期性不确定的，可以通过傅里叶变换计算数据周期。</p>
</li>
<li>
<p>确定拆分规则<br />
拆分规则，是选择加法方式还是乘法方式。</p>
</li>
<li>
<p>加法方式：<br />
原始数据 = 平均季节数据 + 趋势数据 + 残差</p>
</li>
<li>
<p>乘法方式：<br />
原始数据 = 季节数据 * 趋势数据 * 残差</p>
</li>
<li>
<p>计算趋势数据</p>
</li>
<li>计算平均季节数据</li>
<li>计算平均残差数据</li>
</ol>
<h3 id="522">5.2.2. 经典时间序列分解法</h3>
<h4 id="5221">5.2.2.1. 原理</h4>
<p>经典的时间序列分解算法（Classical decomposition），起于1920年，直到1950年之前仍在广泛使用。经典算法步骤相对简单，同时也是很多其他分解算法的基础。经典分解法是假设<strong>周期性成分在每个周期内都是相同的</strong>（【例如每年的月周期成分都相同】）。</p>
<p><strong>加法模式分解</strong><br />
步骤 1 ：计算趋势周期项 $T_t$ (移动平均MA)<br />
步骤 2 ：计算去趋势序列 $Z =y-T_t$<br />
步骤 3 ：估计每个季度的季节项 $S_t$<br />
步骤 4 ：计算残差项。$R_t= y-T_t-S_t$</p>
<p><strong>乘法模式分解</strong></p>
<p>经典乘法分解与加法分解十分相似，只不过是用除法代替了减法。</p>
<p>步骤 1 ：计算趋势周期项$T_t$ (移动平均MA)<br />
步骤 2 ：计算去趋势序列 $Z =y/T_t$<br />
步骤 3 ：估计每个季度的季节项 $S_t$<br />
步骤 4 ：计算残差项。$R_t= y/(T_t*S_t)$</p>
<p><strong>缺点</strong></p>
<ol>
<li>造成序列数据缺失。前几个项 和后几个项数据缺失</li>
<li>T_t 趋势数据收到极值影响。T_t倾向于反应对快速上升或快速下降</li>
<li>假设S_t 是重复的，对某些场景不适合。无法捕捉季节项S_t随时间变化而变化</li>
<li>对存在异常值数据处理robust。</li>
</ol>
<h4 id="5222">5.2.2.2. 使用</h4>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">statsmodels.tsa.seasonal</span> <span class="kn">import</span> <span class="n">seasonal_decompose</span>

<span class="n">decomposition</span><span class="o">=</span><span class="n">seasonal_decompose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s">&#39;additive&#39;</span><span class="p">,</span> <span class="n">filt</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">two_sided</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">extrapolate_trend</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">trend</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">trend</span>
<span class="n">seasonal</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">seasonal</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">resid</span>
<span class="c"># residual: np.array()</span>

<span class="n">decomposition</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="" src="../../../../attach/images/2020-08-27-11-10-46.png" /></p>
<div class="hlcode"><pre><span class="c"># model:str {“additive”, “multiplicative”}  加法模型 乘法模型表示的</span>
<span class="c"># np_series:时间序列，series类型; </span>

<span class="c"># Filt : 过滤参数，用来过滤掉季节性成分(seasonal)和趋势成分(trend)。可以设置你自己的过滤矩阵，也可以直接设置该参数等于None(default)。当Filt设置自定义为None时，里面代码会根据你的period给你一个Filt矩阵，因为这个在计算时是必须要有的。</span>

<span class="c">#当不设置filt参数时，即filt=None时，period为偶数时：</span>


<span class="c">#当不设置filt参数时，period为奇数时：</span>

<span class="c"># 过滤矩阵确定下来后，过滤时所使用的具体移动平均方法，由two_sided的参数决定。</span>
<span class="c"># freq:周期，这里为1440分钟，即一天; </span>
<span class="c"># two_sided:观察下图2、4行图，左边空了一段，如果设为True，则会出现左右两边都空出来的情况，False保证序列在最后的时间也有数据，方便预测。</span>
</pre></div>


<h3 id="523-x11">5.2.3. X11分解法</h3>
<h4 id="5231">5.2.3.1. 原理</h4>
<p>X11分解法（X11 decomposition）是季度性数据和月度数据的分解算法。它发明于美国人口普查局和加拿大统计局。</p>
<p>这方法是基于经典分解法的，但是包括很多其他的步骤和特点来客服经典分解法的一些不足。特别的，所有的数据点的趋势成分都可以得到（【经典分解法最开始和最后的部分数据无法计算得到移动平均值】），周期成分允许随着时间变化。X11有一些 复杂的方法来处理交易日、假期、一些已知的影响因素的影响。它同时处理了加性模型和乘性模型。这个过程是全自动的，而且对于时间序列中的异常值和数据平平变动很鲁棒。</p>
<p>X11方法的细节可以参考 Dagum, E. B., &amp; Bianconcini, S. (2016). Seasonal adjustment methods and real time trend-cycle estimation. Springer。</p>
<h3 id="524-seats">5.2.4. SEATS分解</h3>
<h4 id="5241">5.2.4.1. 原理</h4>
<p><code>SEATS</code>是指<code>Seasonal Extraction in ARIMA Time Series</code>。这个方法是由西班牙银行开发的，现在被广泛应用在各国的政府部门中。</p>
<p><strong>缺点</strong></p>
<p>这个算法只是针对季度性和月度数据。因此天级数据、小时级数据或者周数据，需要其他的方法。</p>
<p>详细的算法过程请参考 Dagum, E. B., &amp; Bianconcini, S. (2016). Seasonal adjustment methods and real time trend-cycle estimation. Springer。</p>
<h3 id="525-stl">5.2.5. STL 分解法</h3>
<h4 id="5251">5.2.5.1. 原理</h4>
<p>STL (Seasonal-Trend decomposition procedure based on Loess) 为时序分解中一种常见的算法，是时间序列分解的一种versatile和鲁棒的方法，基于LOESS将某时刻的数据分解为趋势分量（trend component）、周期分量（seasonal component）和余项（remainder component），其中Loess是一种鲁棒的回归算法。</p>
<p>STL（Seasonal + Trend + Loess）</p>
<p>STL分为内循环（inner loop）与外循环（outer loop），其中内循环主要做了趋势拟合与周期分量的计算。假定、为内循环中第k-1次pass结束时的趋势分量、周期分量，初始时。</p>
<h5 id="52511-lowess">5.2.5.1.1. LOWESS 回归</h5>
<p>用kNN做平均回归：</p>
<p>$$ f(x)^=Ave(yi|xi∈Nk(x))$$</p>
<p>其中，Nk(x)为距离点x最近k个点组成的邻域集合（neighborhood set）。这种邻域平均回归存在很多缺点：</p>
<p>没有考虑到不同距离的邻近点应有不同的权重；<br />
拟合的曲线不连续（discontinuous），如下图。</p>
<p>因此引入kernel加权平滑：</p>
<p>$$ f(x0)^=∑Ni=1Kλ(x0,xi)yi∑Ni=1Kλ(x0,xi)$$</p>
<p>比如，Epanechnikov 二次kernel：</p>
<p>$$ Kλ(x0,xi)=D(|x0−xi|λ)$$</p>
<p>$$ D(t)={34(1−t2)0for|t|&lt;1 otherwise } $$</p>
<p>其中，λ为kernel的参数，称之为window width。对于kNN，只考虑最近的k个点影响；基于此，</p>
<p>$$ λ=|x0−x[k]|$$</p>
<p>其中，x[k]为距离x0第k近的点。如上图，经kernel加权平滑后，回归拟合的曲线为连续的了。但是，这种kernel回归同样存在着边界（boundary）问题，如下图：</p>
<p>对于x序列的开始与结束区段的点，其左右邻域是不对称的，导致了平滑后的值偏大或偏小。因此，需要对权值做再修正，假定对$x_0$的估计值：</p>
<p>f(x0)^=∑j=0dβjxj0<br />
定义目标函数：</p>
<p>minβ∑i=1NKλ(x0,xi)[yi−∑j=0dβjxji]2<br />
令</p>
<p>minΔ(Y−BΔ)TWx0(Y−BΔ)<br />
求偏导，可得到</p>
<p>Δ=(BTWx0B)−1(BTWx0Y)<br />
那么，估计值</p>
<p>f(x0)^=e(x0)(BTWx0B)−1(BTWx0Y)=∑iwi(x0)yi<br />
其中，e(x0)=(1,x0,⋯,xd0)。上述回归方法称之为<code>LOWESS</code> (Local Weighted regression)。</p>
<p>详细内容请参考 Cleveland, R. B., Cleveland, W. S., McRae, J. E., &amp; Terpenning, I. J. (1990). STL: A seasonal-trend decomposition procedure based on loess. Journal of Official Statistics, 6(1), 3–33.</p>
<h4 id="5252">5.2.5.2. 特点</h4>
<p>相比于经典分解法、SEATS和X-11分解法STL分解法有几点优势：</p>
<ol>
<li>
<p>与SEATS和X-11不同的是，STL可以处理任何类型的季节性，不仅仅是月度数据和季度数据。</p>
</li>
<li>
<p>季节项可以随时间变化而变换，并且变化的速率可以由用户掌控。</p>
</li>
<li>
<p>趋势-周期项的平滑程度也可以由用户掌控。</p>
</li>
<li>
<p>可以不受离群点干扰（例如，用户可以指定一个稳健的分解）</p>
</li>
</ol>
<p>另一方面，STL也有一些不足之处。具体来讲，它不能自动地处理交易日或是其他有变动的日子，并且它提供了处理加法分解的方式。</p>
<p>为了得到乘法分解我们可以首先对数据取对数，然后对各成分进行反向变换。对数据进行  0&lt;λ&lt;1的Box-Cox变换可以得到加法分解与乘法分解。 其中  λ=0的值对应于乘法分解， λ=1等价于加法分解。</p>
<p>开始学习如何使用STL的最好方法是查看一些示例并对设置进行尝试。如图6.2展示了STL应用于电气设备订单数据的一个例子。 如图6.13显示了一种替代的STL分解，其中趋势-周期项更灵活，季节项不随时间变化，并且更加稳健。在这里，更明显的是，在该系列的末尾出现了向下转向，并且2009中的订单量异常低（对应于余数成分中的一些大的负值）。</p>
<h4 id="5253">5.2.5.3. 使用</h4>
<p>使用STL时要选择的两个主要参数是<br />
1. 趋势-周期窗口(t.window) 和<br />
2. 季节性窗口(s.window)。</p>
<p>这些参数控制了趋势-周期项和季节项的变化速度，它们的值越小允许变化的速度越快。在估计趋势-周期项和季节项的时候 t.window和 s.window都需要是奇数，并且所用的数据年份应是连续的。用户必须设定 s.window，因为它没有默认值，如果将该值设为无穷大就相当于令季节项为周期性的（即，各年相同）。t.window是可选项，若没有填写它则使用默认值。</p>
<p>mstl() 函数提供了一方便的自动STL分解，其中s.window=13，t.window也是自动选择的。它一般情况下平衡了季节性过拟合与允许其随时间缓慢变化。但是与其他自动化过程一样，对于某些时间序列默认设置需要调整。</p>
<p>同本书中讨论的其他分解方法一样，要获取如图6.8中的各个分量，使用 seasonal() 函数获取季节项，用 trendcycle() 函数获取趋势-周期项，用 remainder()函数获取残差项。 seasadj() 函数可以用于计算经季节调整后的时间序列。</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">statsmodels</span>

<span class="n">statsmodels</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">seasonal</span><span class="o">.</span><span class="n">STL</span><span class="p">(</span><span class="n">endog</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">seasonal</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">trend</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">low_pass</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">seasonal_deg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">trend_deg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">low_pass_deg</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">robust</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">seasonal_jump</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">trend_jump</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">low_pass_jump</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p><img alt="" src="../../../../attach/images/2020-08-27-16-36-57.png" /></p>
<h2 id="53-emd">5.3. 经验模态分解(EMD)</h2>
<p>经验模态分解(EMD)的基本思想：将一个频率不规则的波化为多个单一频率的波+残波的形式。<br />
$$原波形 =X_n= ∑IMFs + 余波$$</p>
<div class="hlcode"><pre><span class="n">python</span><span class="err">安装</span>
<span class="o">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">EMD</span><span class="o">-</span><span class="n">signal</span>

<span class="n">from</span> <span class="n">PyEMD</span> <span class="n">import</span> <span class="n">EMD</span>
<span class="n">import</span> <span class="n">numpy</span> <span class="n">as</span> <span class="n">np</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">random</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">emd</span> <span class="o">=</span> <span class="n">EMD</span><span class="p">()</span>
<span class="n">IMFs</span> <span class="o">=</span> <span class="n">emd</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</pre></div>


<div class="hlcode"><pre><span class="n">from</span> <span class="n">pyhht</span><span class="p">.</span><span class="n">emd</span> <span class="n">import</span> <span class="n">EMD</span>
<span class="n">decomposer</span> <span class="o">=</span> <span class="n">EMD</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>               
</pre></div>


<h1 id="6">6. 时间序列预测</h1>
<h2 id="61">6.1. 基本步骤</h2>
<h2 id="62">6.2. 任务分类</h2>
<h3 id="621">6.2.1. 一元时序时间预测</h3>
<h4 id="6211">6.2.1.1. 平稳性时序预测</h4>
<p>常见的分析方法都是建立在统计学基础上，例如ARMA系列（包括AR，MA，ARMA，ARIMA），这类方法需要满足一些假设（例如平稳性假设等）</p>
<h4 id="6212">6.2.1.2. 差分时序数据结构</h4>
<p>自变量就是历史时间点的数值，因变量就是待预测时间点的数值。这样抛开所有的假设就可以使用很多方法，例如神经网络（BP，RBF之类的）或是一些深度学习的方法（LSTM）。</p>
<p>的问题，这种处理方式一般都在一些特定的领域，比如水动力学模型之类的。<br />
当上面的步骤走完之后，就可以对数据进行预测了，也就是时间序列建模的主要目标之一，预测该序列未来的取值，此外我们要评估预测的精度。一般采用最小均方误差标准。</p>
<p><img alt="" src="../../../../attach/images/2019-10-18-16-20-30.png" /></p>
<h3 id="622">6.2.2. 多元时序时间预测</h3>
<h2 id="63">6.3. 前处理</h2>
<h3 id="631">6.3.1. 频域</h3>
<h3 id="632">6.3.2. 时域处理</h3>
<h4 id="6321">6.3.2.1. 异常检测</h4>
<div class="hlcode"><pre><span class="n">digraph</span> <span class="n">a</span><span class="p">{</span>
    <span class="err">时序数据</span><span class="o">-&gt;</span><span class="err">分解得到残差数据</span><span class="n">R_t</span><span class="o">-&gt;</span><span class="err">残差数据符合正太分布</span><span class="o">-&gt;</span><span class="s">&quot;3sigma 异常检测&quot;</span>
<span class="p">}</span>
</pre></div>


<p>数据如果有异常，都会体现在残差数据集中。我们怎么从残差数据中早出有问题的数据时间点呢？我理解的会有下面几种方式：</p>
<ol>
<li>
<p>确认残差数据满足正太分布，或者近似正太分布，可以计算出残差数据集的标准差，常规方式是数据点与均值的差值绝对值在3倍标准差外，则认为是异常点，也就是3sigma方案。也有例外，下图的残差数据集可能不能被上述方法将异常检测出来，这段数据连续几分钟都是在3倍标准差内，但是出现这种的可能性（1-99.7%）^n，这种情况出现的概率相当低，如果出现也应该被识别为异常点。</p>
</li>
<li>
<p>使用历史数据分段平均的方式，对我们的原始数据进行未来数据点补全，对得到的新数据集使用STL方法去除残差数据，得到业务数据的基线，通过基线与真实值的比对判断是否是异常点。</p>
</li>
</ol>
<h2 id="64">6.4. 模型评价与选择</h2>
<h3 id="641-aicbic">6.4.1. 模型选择AIC与BIC：选择更简单的模型</h3>
<p>1.AIC：赤池信息准则（Akaike Information Criterion，$AIC$）<br />
$$AIC=2k-2ln⁡(L)$$</p>
<p>其中：k是参数的数量，L是似然函数。假设条件是模型的误差服从独立正态分布。</p>
<p>2.BIC：贝叶斯信息准则（Bayesian Information Criterion，$BIC$）<br />
$$BIC=kln(n)-2ln⁡(L)$$<br />
其中：$k$为模型参数个数，$n$为样本数量，$L$为似然函数</p>
<h4 id="6411-armapq-p-q">6.4.1.1. 示例：ARMA(p,q) 模型中p q参数的确定</h4>
<p>已知 p, q的上限 P_0,Q_0。存在一对(k,j)<br />
$$0&lt;=k&lt;=P_0,0&lt;j&lt;P_0$$</p>
<p>$$L=\sigma^2(k,j)$$</p>
<p>$$AIC(k,j)=ln(\sigma^2(k,j))$$<br />
AIC(k,j)的最小值点(p,q)称为的AIC定阶. 如果最小值不惟一, 应先取最小的, 然后取最小的.<br />
<img alt="" src="../../../../attach/images/2019-10-26-11-27-12.png" /></p>
<h3 id="642">6.4.2. 模型评估</h3>
<p>模型诊断一般包括两个方面，一个是残差的检验分析，一个是关于模型过度拟合和参数冗余的问题，总体原则是尽量选择简单的模型。</p>
<h4 id="6421">6.4.2.1. 残差检验分析</h4>
<p>如果模型足够准确，残差应该为白噪声<br />
对于残差检验分析还有很多的方法，这里只列出常见的方法以及要检验的内容：</p>
<ol>
<li>
<p>残差图肉眼简单查看；</p>
</li>
<li>
<p>ARIMA模型的残差是否是平均值为0且方差为常数的正态分布；</p>
</li>
<li>
<p>QQ图：线性即正态分布；</p>
</li>
<li>
<p>Ljung-Box检验：独立性</p>
</li>
</ol>
<h3 id="643">6.4.3. 过度拟合和参数冗余</h3>
<p>对于统计建模或者是机器学习，我们一般都需要模型过拟合的问题，同样的，于时间序列而言，过度拟合和参数冗余也是不容忽视的问题：</p>
<ol>
<li>
<p>在过度拟合时，不要同时增加AR和MA部分的阶数</p>
</li>
<li>
<p>例如：如果拟合了MA(1)模型后，残差在2阶滞后处仍存在明显的相关性，那么应该尝试MA(2)，而不是ARMA(1,1)模型。</p>
</li>
</ol>
<h1 id="7">7. 时间序列预测方法（模型）</h1>
<h2 id="71">7.1. 平均注意力预测</h2>
<h3 id="711-ma">7.1.1. 移动平均MA</h3>
<p>此方法中，所有未来值的预测值等于历史数据的平均值。我们把历史数据记作 <br />
$$X={ x_1,x_2,x_3...x_n}$$</p>
<p>预测值就可以表示为：<br />
$$x_{n+1}=mean(X)$$</p>
<h2 id="72">7.2. 近注意力</h2>
<p>观察值越近，相应的权重越高</p>
<h3 id="721-naive">7.2.1. Naïve 方法</h3>
<p>在 naïve 预测方法中，我们简单地将所有预测值设为最后一次的观测值，即：</p>
<p>$$x_{n+1}=x_n$$</p>
<p>这种方法在很多经济和金融时间序列预测中表现得非常好。</p>
<ul>
<li>季节性 Naïve 方法 </li>
</ul>
<p>将每个预测值设为同一季节的前一期观测值（例如：去年的同一个月）</p>
<p>$$X_{t+s}={x_{1+s},x_{2+s}..x_{n+s}}=X_{t}={ x_1,x_2,x_3...x_n}$$</p>
<h3 id="722">7.2.2. 指数平滑</h3>
<p>换句话说，观察值越近，相应的权重越高。该框架能够快速生成可靠的预测结果，并且适用于广泛的时间序列，这是一个巨大的优势并且对于工业应用来说非常重要。</p>
<h4 id="_1">权重移动平均</h4>
<p>Weighted Moving Average(WMA) in Python<br />
The simple moving average is very naïve as it gives equal weightage to all the values from the past. However it may make much more sense to give more weightage to recent values assuming recent data is closely related to actual values.</p>
<p>To calculate WSMA all we do is multiply each observation in past by certain weights. For example we can give 6 weightage to recent value and 1 to the last value in the 6 week rolling window.</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">random</span>
<span class="n">rand</span> <span class="o">=</span> <span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span>  <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">110</span><span class="p">)]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">data</span><span class="p">[</span><span class="s">&quot;Sales&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">])</span>
<span class="n">sum_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s">&#39;WMA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;Sales&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">sum_weights</span><span class="p">,</span> <span class="n">raw</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">&#39;WMA&#39;</span><span class="p">])</span>
</pre></div>


<h3 id="723-ar">7.2.3. 自回归模型 AR</h3>
<p>描述<strong>当前值</strong>与<strong>历史值</strong>之间的关系，用变量自身的历史时间数据对自身进行预测；</p>
<p>自回归模型必须满足<strong>平稳性</strong>的要求；</p>
<p><code>p阶</code>自回归过程的公式定义：<br />
   $$y_{t}=u_{t}+\sum_{i=1}^{p}γ_{i} y_{t-i} +ϵ_{t} $$</p>
<p>其中：<br />
$y_{t}$是当前值;<br />
$u_{t}$是常数项;<br />
$p$ 是阶数;<br />
$γ_{i}$是自相关系数;<br />
$ϵ_t$ 是误差</p>
<p>自回归模型的限制:<br />
1. 自回归模型是用自身的数据来进行预测；<br />
2. 必须具有平稳性；<br />
3. 必须具有自相关性，如果自相关系数小于0.5，则不宜采用；<br />
4. 自回归只适用于预测与自身前期相关的现象</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">AR</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AR</span><span class="p">(</span><span class="n">data_ts</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="c">#q=0</span>
</pre></div>


<h3 id="724-ma">7.2.4. 移动平均模型 MA</h3>
<p>移动平均模型关注的是自回归模型中的误差项的累加。 <br />
<code>q阶</code>移动平均过程的公式定义：<br />
$$y_{t}=u+\sum_{i=1}^{q}θ_{i} ϵ_{t-i} +ϵ_{t}$$<br />
移动平均法能有效地<code>消除预测中的随机波动</code></p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">ARMA</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ARMA</span><span class="p">(</span><span class="n">data_ts</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">q</span><span class="p">))</span>
<span class="c">#p=0</span>
</pre></div>


<h3 id="725-arma">7.2.5. 自回归移动平均模型 ARMA</h3>
<p>自回归AR与移动平均MA的结合；<br />
公式定义：</p>
<p>$$y_t=u+\sum_{i=1}^pγ_{i} y_{t-i} +\sum_{i=1}^qθ_i ϵ_{t-i}+ϵ_t $$</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">ARMA</span>

<span class="n">tempModel</span> <span class="o">=</span> <span class="n">ARMA</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c"># 产看预测的结果</span>
<span class="n">tempModel</span><span class="o">.</span><span class="n">plot_predict</span><span class="p">()</span>


<span class="n">tempMode</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">ARMA</span> <span class="n">Model</span> <span class="n">Results</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>  <span class="n">get_buy_ratio</span>   <span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>   <span class="mi">167</span>
<span class="n">Model</span><span class="p">:</span>  <span class="n">ARMA</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="n">Log</span> <span class="n">Likelihood</span>  <span class="mf">376.798</span>
<span class="n">Method</span><span class="p">:</span> <span class="n">css</span><span class="o">-</span><span class="n">mle</span> <span class="n">S</span><span class="o">.</span><span class="n">D</span><span class="o">.</span> <span class="n">of</span> <span class="n">innovations</span> <span class="mf">0.025</span>
<span class="n">Date</span><span class="p">:</span>   <span class="n">Fri</span><span class="p">,</span> <span class="mi">31</span> <span class="n">Jan</span> <span class="mi">2020</span>    <span class="n">AIC</span> <span class="o">-</span><span class="mf">721.595</span>
<span class="n">Time</span><span class="p">:</span>   <span class="mi">10</span><span class="p">:</span><span class="mi">51</span><span class="p">:</span><span class="mi">43</span>    <span class="n">BIC</span> <span class="o">-</span><span class="mf">671.707</span>
<span class="n">Sample</span><span class="p">:</span> <span class="mi">0</span>   <span class="n">HQIC</span>    <span class="o">-</span><span class="mf">701.347</span>
<span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span> <span class="n">z</span>   <span class="n">P</span><span class="o">&gt;|</span><span class="n">z</span><span class="o">|</span>   <span class="p">[</span><span class="mf">0.025</span>  <span class="mf">0.975</span><span class="p">]</span>
<span class="n">const</span>   <span class="mf">0.0951</span>  <span class="mf">0.009</span>   <span class="mf">10.309</span>  <span class="mf">0.000</span>   <span class="mf">0.077</span>   <span class="mf">0.113</span>
<span class="n">ar</span><span class="o">.</span><span class="n">L1</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">1.1934</span>  <span class="mf">0.142</span>   <span class="mf">8.425</span>   <span class="mf">0.000</span>   <span class="mf">0.916</span>   <span class="mf">1.471</span>
<span class="n">ar</span><span class="o">.</span><span class="n">L2</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="o">-</span><span class="mf">0.3745</span> <span class="mf">0.178</span>   <span class="o">-</span><span class="mf">2.098</span>  <span class="mf">0.038</span>   <span class="o">-</span><span class="mf">0.724</span>  <span class="o">-</span><span class="mf">0.025</span>
<span class="n">ar</span><span class="o">.</span><span class="n">L3</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.9050</span>  <span class="mf">0.270</span>   <span class="mf">3.355</span>   <span class="mf">0.001</span>   <span class="mf">0.376</span>   <span class="mf">1.434</span>
<span class="n">ar</span><span class="o">.</span><span class="n">L4</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="o">-</span><span class="mf">0.8102</span> <span class="mf">0.186</span>   <span class="o">-</span><span class="mf">4.350</span>  <span class="mf">0.000</span>   <span class="o">-</span><span class="mf">1.175</span>  <span class="o">-</span><span class="mf">0.445</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L1</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="o">-</span><span class="mf">0.4921</span> <span class="mf">0.152</span>   <span class="o">-</span><span class="mf">3.243</span>  <span class="mf">0.001</span>   <span class="o">-</span><span class="mf">0.789</span>  <span class="o">-</span><span class="mf">0.195</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L2</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.1812</span>  <span class="mf">0.148</span>   <span class="mf">1.221</span>   <span class="mf">0.224</span>   <span class="o">-</span><span class="mf">0.110</span>  <span class="mf">0.472</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L3</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="o">-</span><span class="mf">0.9148</span> <span class="mf">0.230</span>   <span class="o">-</span><span class="mf">3.974</span>  <span class="mf">0.000</span>   <span class="o">-</span><span class="mf">1.366</span>  <span class="o">-</span><span class="mf">0.464</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L4</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.2433</span>  <span class="mf">0.122</span>   <span class="mf">1.994</span>   <span class="mf">0.048</span>   <span class="mf">0.004</span>   <span class="mf">0.482</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L5</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="o">-</span><span class="mf">0.0706</span> <span class="mf">0.113</span>   <span class="o">-</span><span class="mf">0.623</span>  <span class="mf">0.534</span>   <span class="o">-</span><span class="mf">0.293</span>  <span class="mf">0.151</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L6</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.0391</span>  <span class="mf">0.113</span>   <span class="mf">0.346</span>   <span class="mf">0.730</span>   <span class="o">-</span><span class="mf">0.182</span>  <span class="mf">0.261</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L7</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.1301</span>  <span class="mf">0.107</span>   <span class="mf">1.217</span>   <span class="mf">0.225</span>   <span class="o">-</span><span class="mf">0.079</span>  <span class="mf">0.340</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L8</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.0610</span>  <span class="mf">0.127</span>   <span class="mf">0.481</span>   <span class="mf">0.631</span>   <span class="o">-</span><span class="mf">0.188</span>  <span class="mf">0.310</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L9</span><span class="o">.</span><span class="n">get_buy_ratio</span> <span class="mf">0.1128</span>  <span class="mf">0.101</span>   <span class="mf">1.121</span>   <span class="mf">0.264</span>   <span class="o">-</span><span class="mf">0.084</span>  <span class="mf">0.310</span>
<span class="n">ma</span><span class="o">.</span><span class="n">L10</span><span class="o">.</span><span class="n">get_buy_ratio</span>    <span class="mf">0.1229</span>  <span class="mf">0.096</span>   <span class="mf">1.282</span>   <span class="mf">0.202</span>   <span class="o">-</span><span class="mf">0.065</span>  <span class="mf">0.311</span>
<span class="n">Roots</span>
<span class="n">Real</span>    <span class="n">Imaginary</span>   <span class="n">Modulus</span> <span class="n">Frequency</span>
<span class="n">AR</span><span class="o">.</span><span class="mi">1</span>    <span class="o">-</span><span class="mf">0.4414</span> <span class="o">-</span><span class="mf">0.9992j</span>    <span class="mf">1.0923</span>  <span class="o">-</span><span class="mf">0.3162</span>
<span class="n">AR</span><span class="o">.</span><span class="mi">2</span>    <span class="o">-</span><span class="mf">0.4414</span> <span class="o">+</span><span class="mf">0.9992j</span>    <span class="mf">1.0923</span>  <span class="mf">0.3162</span>
<span class="n">AR</span><span class="o">.</span><span class="mi">3</span>    <span class="mf">0.9999</span>  <span class="o">-</span><span class="mf">0.1861j</span>    <span class="mf">1.0171</span>  <span class="o">-</span><span class="mf">0.0293</span>
<span class="n">AR</span><span class="o">.</span><span class="mi">4</span>    <span class="mf">0.9999</span>  <span class="o">+</span><span class="mf">0.1861j</span>    <span class="mf">1.0171</span>  <span class="mf">0.0293</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">1</span>    <span class="mf">0.9786</span>  <span class="o">-</span><span class="mf">0.2058j</span>    <span class="mf">1.0000</span>  <span class="o">-</span><span class="mf">0.0330</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">2</span>    <span class="mf">0.9786</span>  <span class="o">+</span><span class="mf">0.2058j</span>    <span class="mf">1.0000</span>  <span class="mf">0.0330</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">3</span>    <span class="mf">0.7272</span>  <span class="o">-</span><span class="mf">1.0988j</span>    <span class="mf">1.3177</span>  <span class="o">-</span><span class="mf">0.1570</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">4</span>    <span class="mf">0.7272</span>  <span class="o">+</span><span class="mf">1.0988j</span>    <span class="mf">1.3177</span>  <span class="mf">0.1570</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">5</span>    <span class="o">-</span><span class="mf">0.5196</span> <span class="o">-</span><span class="mf">0.9153j</span>    <span class="mf">1.0525</span>  <span class="o">-</span><span class="mf">0.3322</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">6</span>    <span class="o">-</span><span class="mf">0.5196</span> <span class="o">+</span><span class="mf">0.9153j</span>    <span class="mf">1.0525</span>  <span class="mf">0.3322</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">7</span>    <span class="o">-</span><span class="mf">0.1605</span> <span class="o">-</span><span class="mf">1.2826j</span>    <span class="mf">1.2926</span>  <span class="o">-</span><span class="mf">0.2698</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">8</span>    <span class="o">-</span><span class="mf">0.1605</span> <span class="o">+</span><span class="mf">1.2826j</span>    <span class="mf">1.2926</span>  <span class="mf">0.2698</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">9</span>    <span class="o">-</span><span class="mf">1.4844</span> <span class="o">-</span><span class="mf">0.5732j</span>    <span class="mf">1.5912</span>  <span class="o">-</span><span class="mf">0.4413</span>
<span class="n">MA</span><span class="o">.</span><span class="mi">10</span>   <span class="o">-</span><span class="mf">1.4844</span> <span class="o">+</span><span class="mf">0.5732j</span>    <span class="mf">1.5912</span>  <span class="mf">0.4413</span>
</pre></div>


<h3 id="726-arima">7.2.6. 差分自回归移动平均模型 ARIMA</h3>
<p>差分自回归移动平均模型(Autoregressive Integrated Moving Average Model，简记ARIMA)。假设一个随机过程有d个单位根，经过d次差分后可变成一个<strong>平稳</strong>的<code>自回归移动平均过程</code>，则称该过程为<code>差分自回归移动平均过程</code></p>
<ul>
<li>AR是自回归， $p$为自回归项； </li>
<li>MA为移动平均，$q$为移动平均项数，</li>
<li>$d$为时间序列成为平稳时所做的差分次数，如一阶差分：时间序列在$t$与$t-1$时刻的差值；<br />
$$X={x1,x2..x_t}$$</li>
<li>将序列$X$转换成d阶差分序列$\Delta^d X$<br />
$$\Delta ^d X={\Delta x_1,\Delta x_2,...,\Delta x_{t-d}}$$</li>
<li>d阶差分序列$\Delta^d X$ 构建ARMA 模型</li>
</ul>
<p>原理：将非平稳时间序列转化为平稳时间序列然后将因变量仅对它的滞后值以及随机误差项的现值和滞后值进行回归所建立的模型</p>
<p><strong>ARIMA（p,d,q）参数确定</strong></p>
<table>
<thead>
<tr>
<th>模型</th>
<th align="center">ACF</th>
<th align="right">PACF</th>
</tr>
</thead>
<tbody>
<tr>
<td>AR (P )</td>
<td align="center">拖尾，衰减趋于零</td>
<td align="right">P阶后截尾</td>
</tr>
<tr>
<td>MA(q)</td>
<td align="center">q阶后截尾</td>
<td align="right">拖尾，衰减趋于零</td>
</tr>
<tr>
<td>ARMA(p,q)</td>
<td align="center">拖尾，q阶后衰减趋于零</td>
<td align="right">拖尾，P阶后衰减趋于零</td>
</tr>
</tbody>
</table>
<p>截尾：落在置信区间内（95%的点都符合该规则）</p>
<blockquote>
<p>$AR(p)$ 看$PACF$<br />
$MA(q)$ 看$ACF$</p>
</blockquote>
<p>下图是Python做出的ACF和PACF图：<br />
<img alt="这里写图片描述" src="http://img.blog.csdn.net/20171023102400132?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQva2ljaWxvdmU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" /></p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">ARIMA</span>


<span class="n">tempModel</span> <span class="o">=</span> <span class="n">ARIMA</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">q</span><span class="p">))</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
</pre></div>


<h2 id="73">7.3. 选择注意力</h2>
<h3 id="731">7.3.1. 漂移法（趋势法）</h3>
<p><strong>只注意第一个观测点和最后一个观测点</strong></p>
<p>趋势法（漂移法）这相当于把第一个观测点和最后一个观测点连成一条直线并延伸到未来预测点。</p>
<p>$$ x_{n+t}=x_n+t*\frac{x_n-x_1}{n} $$</p>
<p><img alt="" src="../../../../attach/images/2019-10-19-10-28-40.png" /></p>
<h3 id="732">7.3.2. 马尔可夫链</h3>
<h3 id="733">7.3.3. 神经网络</h3>
<p>主要设计思想：</p>
<p>CNN捕捉短期局部依赖关系<br />
RNN捕捉长期宏观依赖关系<br />
Attention为重要时间段或变量加权<br />
AR捕捉数据尺度变化(没太搞懂啥意思~)</p>
<h2 id="74">7.4. 预测区间</h2>
<p>一个预测区间反映了单个数值的不确定性，给出了一定置信度下的置信区</p>
<p>例如，假设预测误差为正态分布，则置信度为95%的第h步的预测预测区间是h步预测标准差的预测分布的估计值，更一般地，可以将预测区间写为<br />
$$ x_{t+h} \pm (k*\sigma_h) $$</p>
<p>式中：<br />
$x_{t+h}$: 为预测值<br />
$k$: 为与置信度概率有关的乘子<br />
$sigma_h$: 为h步预测的标准差</p>
<p><strong>乘子k的计算</strong><br />
乘子k取决于置信概率。下表给出了在不同正态分布预测误差范围（置信度）内对应乘子 k值。</p>
<table>
<thead>
<tr>
<th>置信概率百分比</th>
<th>乘子k</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td>0.67</td>
</tr>
<tr>
<td>55</td>
<td>0.76</td>
</tr>
<tr>
<td>60</td>
<td>0.84</td>
</tr>
<tr>
<td>65</td>
<td>0.93</td>
</tr>
<tr>
<td>70</td>
<td>1.04</td>
</tr>
<tr>
<td>75</td>
<td>1.15</td>
</tr>
<tr>
<td>80</td>
<td>1.28</td>
</tr>
<tr>
<td>85</td>
<td>1.44</td>
</tr>
<tr>
<td>90</td>
<td>1.64</td>
</tr>
<tr>
<td>95</td>
<td>1.96</td>
</tr>
<tr>
<td>96</td>
<td>2.05</td>
</tr>
<tr>
<td>97</td>
<td>2.17</td>
</tr>
<tr>
<td>98</td>
<td>2.33</td>
</tr>
<tr>
<td>99</td>
<td>2.58</td>
</tr>
</tbody>
</table>
<p><strong>标准差$\sigma_h$的计算</strong><br />
* 对于一步预测区间<br />
  预测分布的标准差与残差的标准差几乎相同<br />
  $\sigma_h =\sigma_{R_h}$</p>
<p>（事实上，如果没有需要被估计的参数，这两个标准差是相同的，比如 naïve 方法。对于那些有需要估计参数的预测方法，预测分布的标准差略大于残差标准差，尽管这种差异经常被忽略。）<br />
* 对于多步预测区间</p>
<h1 id="9">9. 参考资料</h1>
<ol>
<li>statsmodels  V 0.10.0 太难用了 用V0.11.0</li>
</ol>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>《预测：方法与实践》：https://otexts.com/fppcn/&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>