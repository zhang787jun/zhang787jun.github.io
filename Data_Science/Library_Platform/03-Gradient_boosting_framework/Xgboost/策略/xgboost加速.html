<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>为了更快的xgboost - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Science">Data_Science</a>&nbsp;»&nbsp;<a href="/Wiki/#-Library_Platform">Library_Platform</a>&nbsp;»&nbsp;<a href="/Wiki/#-03-Gradient_boosting_framework">03-Gradient_boosting_framework</a>&nbsp;»&nbsp;<a href="/Wiki/#-Xgboost">Xgboost</a>&nbsp;»&nbsp;<a href="/Wiki/#-策略">策略</a>&nbsp;»&nbsp;为了更快的xgboost</div>
</div>
<div class="clearfix"></div>
<div id="title">为了更快的xgboost</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">时间复杂度</a></li>
<li><a href="#_2">近似贪心算法</a></li>
<li><a href="#_3">缓存排序好的特征</a></li>
<li><a href="#gpu">GPU 加速</a></li>
<li><a href="#_4">减少特征</a></li>
<li><a href="#_5">并行计算</a></li>
<li><a href="#_6">数据并行</a></li>
</ul>
</div>
<h1 id="_1">时间复杂度</h1>
<p>模型计算的时间复杂度 <br />
$$O(n\times d\times K \times \log n)$$</p>
<p>其中 特征排序的时间复杂度 为<br />
$$O(n \log n)$$<br />
xgboost在训练之前，对输入的每个特征进行了预排序。这个是最大时间消耗点。</p>
<ul>
<li><code>K</code> 树的max_depth </li>
<li>n 样本数量</li>
<li>d</li>
</ul>
<h1 id="_2">近似贪心算法</h1>
<div class="hlcode"><pre><span class="c"># 精确贪心算法O(features_counts)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">features_counts</span><span class="p">):</span>
    <span class="n">do</span><span class="o">...</span>

<span class="c"># 近似贪心算法 O(bins_counts)</span>
<span class="n">bins</span><span class="o">=</span><span class="n">func</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bins_counts</span><span class="p">):</span>
    <span class="n">do</span><span class="o">...</span>
<span class="c"># bins_counts&lt;=features_counts</span>
</pre></div>


<p>确定分裂节点时候不使用精确贪心算法，tree methods设置<code>hist</code>、<code>approx</code>，避免使用<code>exact</code>(会对模型最终效果产生影响)</p>
<h1 id="_3">缓存排序好的特征</h1>
<p>$$\gamma$$<br />
依赖框架实现 </p>
<ul>
<li>当数据集大的时候使用近似算法</li>
<li>Block与并行</li>
<li>CPU cache 命中优化</li>
<li>Block预取、Block压缩、Block Sharding等</li>
</ul>
<h1 id="gpu">GPU 加速</h1>
<p>xgboost的GPU 加速只支持 英伟达 显卡的CUDA 上，且只有在 P100 之后的显卡才效率的有显著提高。对Pascal架构之前的显卡会使得计算变得更慢。</p>
<p>参考 ：https://xgboost.readthedocs.io/en/latest/gpu/index.html</p>
<div class="hlcode"><pre><span class="c">#CPU</span>
<span class="n">bst</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mi">1</span><span class="nb">min</span> <span class="mi">15</span><span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">260</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mi">1</span><span class="nb">min</span> <span class="mi">15</span><span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">19.4</span> <span class="n">s</span>

<span class="c">#GPU</span>
<span class="n">bst</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">2.17</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mf">1.14</span> <span class="n">s</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">3.31</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">3.17</span> <span class="n">s</span>
</pre></div>


<p><strong>NOTE</strong><br />
Pascal 架构作为 Maxwell 架构的升级版，2016 发布第一款产品 Tesla P100 (GP100) </p>
<p><strong>使用Pascal架构的相关显卡产品：</strong><br />
1. GeForce系列游戏显卡<br />
GTX1050、1050Ti、1060(3G, 5G, 6G)、1070、1070Ti、1080、1080Ti等 [12] <br />
2. QUADRO系列专业显卡<br />
GP100、P6000、P5000、P4000、P2000、P1000、P600、P400等 [13]</p>
<ol>
<li>Tesla系列加速计算卡<br />
P100、P4、P40 [14] </li>
<li>TITAN显卡<br />
TITAN Xp</li>
</ol>
<h1 id="_4">减少特征</h1>
<p>减少不相关特征及自差异性小特征，降低特征之间的相关行。</p>
<h1 id="_5">并行计算</h1>
<h1 id="_6">数据并行</h1>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>