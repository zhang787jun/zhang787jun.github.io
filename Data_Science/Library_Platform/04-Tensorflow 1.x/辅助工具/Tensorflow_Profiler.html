<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>Tensorflow Profiler 程序性能测试与优化 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Science">Data_Science</a>&nbsp;»&nbsp;<a href="/Wiki/#-Library_Platform">Library_Platform</a>&nbsp;»&nbsp;<a href="/Wiki/#-04-Tensorflow 1.x">04-Tensorflow 1.x</a>&nbsp;»&nbsp;<a href="/Wiki/#-辅助工具">辅助工具</a>&nbsp;»&nbsp;Tensorflow Profiler 程序性能测试与优化</div>
</div>
<div class="clearfix"></div>
<div id="title">Tensorflow Profiler 程序性能测试与优化</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#_1">背景</a></li>
<li><a href="#1-tfprofile">1. 使用tf.profile评估性能</a><ul>
<li><a href="#11-tfprofile">1.1. tf.profile的使用步骤</a></li>
<li><a href="#12">1.2. 评估器实例</a><ul>
<li><a href="#121">1.2.1. 新建评估器实例</a></li>
<li><a href="#122">1.2.2. 实例操作</a></li>
<li><a href="#123">1.2.3. 评估运行并得到结果</a></li>
</ul>
</li>
<li><a href="#13-protobuf">1.3. protobuf格式的数据结构对象</a></li>
<li><a href="#14">1.4. 评估器的选项设置</a><ul>
<li><a href="#141">1.4.1. 记录内容选项</a><ul>
<li><a href="#1411">1.4.1.1. 记录时间和内存消耗</a></li>
<li><a href="#1412">1.4.1.2. 记录浮点运算情况</a></li>
</ul>
</li>
<li><a href="#142">1.4.2. 输出选项</a></li>
<li><a href="#143">1.4.3. 限定选项</a><ul>
<li><a href="#1431-profiler">1.4.3.1. 选择制定profiler节点</a></li>
<li><a href="#1432-profiler">1.4.3.2. 选择消耗时间大于阈值的profiler节点</a></li>
<li><a href="#1433-profiler">1.4.3.3. 选择消耗空间大于阈值的profiler节点</a></li>
<li><a href="#1434-profiler">1.4.3.4. 选择运算大于阈值的profiler节点</a></li>
<li><a href="#1435-profiler">1.4.3.5. 选择参数数量大于阈值的profiler节点</a></li>
</ul>
</li>
<li><a href="#144-">1.4.4. 评估器选项构建器-构建</a></li>
<li><a href="#145">1.4.5. 输出视图</a></li>
</ul>
</li>
<li><a href="#15">1.5. 常用实例</a><ul>
<li><a href="#151-flop">1.5.1. 浮点运算次数 flop</a></li>
<li><a href="#152">1.5.2. 总参数量</a></li>
<li><a href="#153">1.5.3. 统计模型内存和耗时情况</a></li>
<li><a href="#154-profile">1.5.4. 给出使用profile工具给出建议</a></li>
</ul>
</li>
<li><a href="#16-profile">1.6. 基于profile的建议</a></li>
<li><a href="#17-estimatorprofile">1.7. 在estimator中使用profile</a></li>
<li><a href="#18-keras">1.8. 在keras 中使用</a></li>
</ul>
</li>
<li><a href="#2">2. 工具</a><ul>
<li><a href="#21-tensorflow-profiler-ui">2.1. Tensorflow Profiler UI</a><ul>
<li><a href="#211-installation">2.1.1. 安装 Installation</a></li>
<li><a href="#212-profiler">2.1.2. 准备 profiler 文件</a></li>
<li><a href="#213-ui">2.1.3. 启动 UI</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-2">3. 优化策略2</a><ul>
<li><a href="#31">3.1. 硬件</a><ul>
<li><a href="#311">3.1.1. 单机</a><ul>
<li><a href="#3111-cpu">3.1.1.1. CPU 加速</a></li>
<li><a href="#3112-gpu">3.1.1.2. GPU 加速</a></li>
<li><a href="#3113-tpu">3.1.1.3. TPU 加速</a></li>
<li><a href="#3114-io">3.1.1.4. I/O 开销</a></li>
</ul>
</li>
<li><a href="#312">3.1.2. 集群</a></li>
</ul>
</li>
<li><a href="#32-jit">3.2. JIT 编译</a></li>
</ul>
</li>
<li><a href="#4">4. 配置开启即时编译</a></li>
<li><a href="#5">5. 参考资料</a></li>
</ul>
</div>
<h1 id="_1">背景</h1>
<p>和其他程序算法一样，基于tensorflow框架的运行的程序同样需要注重算法效率。<br />
程序的运行优化大致从 <code>算法</code> 和 <code>可调度资源</code> 两方面考虑 </p>
<p>考察算法效率大致从以下几个方面考虑：<br />
1. 时间消耗<br />
2. 内存空间消耗<br />
3. 时间/空间复杂度</p>
<p>考察可调度资源匹配从以下几个方面考虑：<br />
1. 硬件计算能力<br />
2. 调度资源效率<br />
3. 资源瓶颈分析等</p>
<p>同时结合自由的硬件资源，进行协同调度</p>
<h1 id="1-tfprofile">1. 使用tf.profile评估性能</h1>
<p>参考：<br />
1. TensorFlow Profiler and Advisor： https://github.com/tensorflow/tensorflow/tree/r1.3/tensorflow/core/profiler<br />
2. TensorFlow Profiler UI：https://github.com/tensorflow/profiler-ui</p>
<h3 id="11-tfprofile">1.1. tf.profile的使用步骤</h3>
<p>程序性能评估的过程分为4步：<br />
1. 创建评估器 tf.profiler.Profiler 实例 <br />
2. 创建protobuf格式的数据结构对象</p>
<ol>
<li>创建评估器 tf.profiler.Profiler 实例 </li>
</ol>
<div class="hlcode"><pre><span class="n">profiler</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span><span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="c"># profiler 实例</span>
<span class="c"># op_log: optional. tensorflow::tfprof::OpLogProto proto. Used to define extra op types.</span>
</pre></div>


<ol>
<li>创建protobuf格式的数据结构对象</li>
</ol>
<div class="hlcode"><pre><span class="c">#2.1. 保存运行数据的run_metadata数据结构对象，以记录运行时候的每个OP 的运行时间和内存占用数据</span>
<span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">run_metadata</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">config_pb2</span><span class="o">.</span><span class="n">RunMetadata</span>

<span class="c">#2.2. 保存评估器运行参数的run_options数据结构对象 </span>
<span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">run_options</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="n">tensorflow</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">protobuf</span><span class="o">.</span><span class="n">config_pb2</span><span class="o">.</span><span class="n">RunOptions</span>
</pre></div>


<p>RunOptions 设置评估器的运行参数选项，包括:全记录，记录硬件信息，记录软件信息，不记录。</p>
<div class="hlcode"><pre><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span> <span class="err">类</span>
<span class="err">类成员</span>
<span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span>
<span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">HARDWARE_TRACE</span>
<span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">NO_TRACE</span>
<span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">SOFTWARE_TRACE</span>
<span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">TraceLevel</span>
</pre></div>


<ol>
<li>将上述二者结合并评估模型耗时、内存占用、参数数量等情况；</li>
</ol>
<div class="hlcode"><pre><span class="n">op</span><span class="o">=</span><span class="err">···</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">total_steps</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span> <span class="c">#@1</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">add_step</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">run_meta</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span> <span class="c">#@2</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">profile_graph</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="n">profile_graph_opts_builder</span><span class="o">.</span><span class="n">build</span><span class="p">())</span> <span class="c">#@3</span>


<span class="n">profiler</span> <span class="err">分为数据搜集和数据显示两个主要步骤。</span>

<span class="n">graph</span> <span class="n">node</span><span class="err">计算图中的节点每一次执行，记录单步统计数据，主要是执行时间和占用内存，格式参见</span><span class="n">step_stats</span><span class="o">.</span><span class="n">proto</span><span class="err">，作为原始的最小粒度统计数据源；</span>
<span class="c">#@1 每一次session.Run()，所有执行到的graph node的统计数据，都集中汇总保存到 RunMetadata 数据结构中</span>
<span class="c">#@2 用户程序把每一次搜集到的 RunMetadata 添加到profiler实例，做数据累计和加工处理。</span>
<span class="c">#@3 将profiler以某一视图按某一设定输出</span>
</pre></div>


<ol>
<li>profiler 持久后保存/可视化</li>
</ol>
<div class="hlcode"><pre><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">current_dir_path</span><span class="o">+</span><span class="s">&#39;/profile.pd&#39;</span><span class="p">,</span> <span class="s">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">profiler</span><span class="o">.</span><span class="n">serialize_to_string</span><span class="p">())</span>
</pre></div>


<h3 id="12">1.2. 评估器实例</h3>
<h4 id="121">1.2.1. 新建评估器实例</h4>
<div class="hlcode"><pre><span class="n">Profiler</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="c">#graph：tf.Graph。如果为“None”或者未启用“eager执行”，请使用默认图形。</span>
<span class="c">#op_log：可选的。tensorflow :: tfprof :: OpLogProto proto。用于定义额外的op类型。</span>

<span class="n">profile</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
    <span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">run_meta</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">cmd</span><span class="o">=</span><span class="s">&#39;graph&#39;</span><span class="p">,</span> <span class="c"># &#39;op&#39;，&#39;scope&#39;，&#39;graph&#39;,&#39;code&#39;</span>
    <span class="n">options</span><span class="o">=</span><span class="p">{}</span>
<span class="p">)</span>
</pre></div>


<h4 id="122">1.2.2. 实例操作</h4>
<div class="hlcode"><pre><span class="c"># 将run_meta和step 添加到Profiler</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">add_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span><span class="n">run_meta</span><span class="p">)</span> <span class="c"># 添加步骤的统计信息。</span>
<span class="c">#step:int-&gt;0</span>
<span class="c">#run_meta-&gt;run_metadata:</span>

<span class="c">#将ProfileProto序列化为二进制字符串。</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">serialize_to_string</span><span class="p">()</span>  

<span class="c"># 将run_meta输出到log_dir中</span>
<span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">write_op_log</span><span class="p">(</span>
    <span class="n">graph</span><span class="p">,</span>
    <span class="n">log_dir</span><span class="p">,</span>
    <span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">run_meta</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">add_trace</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</pre></div>


<h4 id="123">1.2.3. 评估运行并得到结果</h4>
<div class="hlcode"><pre><span class="n">Advise</span><span class="o">=</span><span class="n">Profiler</span><span class="o">.</span><span class="n">advise</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="c"># 自动检测问题并生成报告,返回一个包含所有检查者的报告的Advise原型。</span>

<span class="n">GraphNodeProto</span><span class="o">=</span><span class="n">Profiler</span><span class="o">.</span><span class="n">profile_graph</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span> <span class="c">#通过数据流图组织图形节点的统计信息。</span>
<span class="n">GraphNodeProto</span><span class="o">=</span><span class="n">Profiler</span><span class="o">.</span><span class="n">profile_name_scope</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="c">#按名称范围组织图形节点的统计信息。</span>
<span class="n">MultiGraphNodeProto</span><span class="o">=</span><span class="n">Profiler</span><span class="o">.</span><span class="n">profile_operations</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span><span class="c">#描述操作类型的统计信息（例如：MatMul，Conv2D）。</span>
<span class="n">MultiGraphNodeProto</span><span class="o">=</span><span class="n">Profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="o">.</span><span class="n">profile_python</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span>  <span class="c">#描述Python代码的统计信息。</span>

<span class="nb">type</span><span class="p">(</span><span class="n">options</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="nb">dict</span> 
</pre></div>


<div class="hlcode"><pre><span class="c"># ----------profile</span>
<span class="n">profile</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
    <span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">run_meta</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">cmd</span><span class="o">=</span><span class="s">&#39;graph&#39;</span><span class="p">,</span> <span class="c"># &#39;op&#39;，&#39;scope&#39;，&#39;graph&#39;,&#39;code&#39;</span>
    <span class="n">options</span><span class="o">=</span><span class="p">{}</span>
<span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">profile</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tfprof_output_pb2</span><span class="o">.</span><span class="n">GraphNodeProto</span>
<span class="c"># 上述等同于--|</span>
<span class="n">Profiler</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">add_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span><span class="n">run_meta</span><span class="p">)</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">profile_graph</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span>

<span class="c">#---------advise</span>
<span class="n">advise</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">advise</span><span class="p">(</span>
    <span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">run_meta</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="n">_DEFAULT_ADVISE_OPTIONS</span>
<span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">advise</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">tfprof_output_pb2</span><span class="o">.</span><span class="n">AdviceProto</span>
<span class="c"># 上述等同于--|</span>
<span class="n">Profiler</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">Profiler</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span><span class="n">op_log</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">add_step</span><span class="p">(</span><span class="n">step</span><span class="p">,</span><span class="n">run_meta</span><span class="p">)</span>
<span class="n">Profiler</span><span class="o">.</span><span class="n">advise</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span>
</pre></div>


<h3 id="13-protobuf">1.3. protobuf格式的数据结构对象</h3>
<p>我们注意到Profiler 运行是输出ProtocolMessage格式统计数据，tf.profile中定义了4种 数结构</p>
<div class="hlcode"><pre><span class="n">class</span> <span class="n">AdviceProto</span><span class="err">：</span><span class="n">ProtocolMessage</span>

<span class="n">class</span> <span class="n">GraphNodeProto</span><span class="err">：</span><span class="n">ProtocolMessage</span>

<span class="n">class</span> <span class="n">MultiGraphNodeProto</span><span class="err">：</span><span class="n">ProtocolMessage</span>

<span class="n">class</span> <span class="n">OpLogProto</span><span class="err">：</span><span class="n">ProtocolMessage</span>
</pre></div>


<h3 id="14">1.4. 评估器的选项设置</h3>
<p>评估器的选项设置options通过字典完成，</p>
<p>tf.profiler.profile中的options可选项为：</p>
<div class="hlcode"><pre><span class="o">-</span><span class="n">max_depth</span> <span class="mi">4</span>       <span class="err">命名空间的深度阈值，超过该阈值的分支不予展示</span>
<span class="o">-</span><span class="n">min_bytes</span> <span class="mi">0</span>       <span class="err">展示占用内存超过该阈值的</span><span class="n">OP</span>
<span class="o">-</span><span class="n">min_micros</span> <span class="mi">10</span>       <span class="err">展示耗时超过该阈值的</span><span class="n">OP</span>
<span class="o">-</span><span class="n">min_params</span>  <span class="mi">0</span>       <span class="err">展示超过该阈值的参数大小的</span><span class="n">OP</span>
<span class="o">-</span><span class="n">min_float_ops</span> <span class="mi">0</span>       <span class="err">展示超过该阈值的浮点计算量的</span> <span class="n">OP</span>
<span class="o">-</span><span class="n">min_occurrence</span>  <span class="mi">0</span>        <span class="err">展示超过该阈值的出现次数的</span> <span class="n">OP</span>
<span class="o">-</span><span class="n">step</span> <span class="o">-</span><span class="mi">1</span>       <span class="err">展示训练时候哪一步的统计情况，默认为最后一步</span>
<span class="o">-</span><span class="n">order_by</span> <span class="n">micros</span>       <span class="err">统计结果排序字段设定</span>
<span class="o">-</span><span class="n">account_type_regexes</span> <span class="n">_trainable_variables</span> 
<span class="n">Selectively</span> <span class="n">counting</span> <span class="n">statistics</span> <span class="n">based</span> <span class="n">on</span> <span class="n">node</span> <span class="n">types</span> <span class="err">，比如这里设定展示可训练变量；</span><span class="n">account_type_regexes</span><span class="o">=</span><span class="p">[</span><span class="err">&#39;</span><span class="p">.</span><span class="o">*</span><span class="n">gpu</span><span class="o">:</span><span class="mf">0.</span><span class="o">*</span><span class="err">&#39;</span><span class="p">]</span> <span class="err">设定展示</span> <span class="n">GPU</span> <span class="err">运行的变量；</span>
<span class="o">-</span><span class="n">start_name_regexes</span> <span class="p">.</span><span class="o">*</span> 
      <span class="err">以下四个选项可以更加灵活的设置展示哪些</span> <span class="n">OP</span> 
<span class="o">-</span><span class="n">trim_name_regexes</span> 
<span class="o">-</span><span class="n">show_name_regexes</span> <span class="n">siamese</span><span class="p">.</span><span class="o">*</span>
<span class="o">-</span><span class="n">hide_name_regexes</span> 
<span class="o">-</span><span class="n">account_displayed_op_only</span> <span class="nb">false</span>
<span class="o">-</span><span class="n">select</span> <span class="n">micros</span>  <span class="err">选择展示的属性</span><span class="p">,</span><span class="err">这里选择查看计算耗时，</span>
<span class="o">-</span><span class="n">output</span> <span class="n">stdout</span><span class="o">:</span> <span class="err">输出方式，这里是标准输出</span>
</pre></div>


<p>参考：https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md</p>
<p>同时选项字典可以通过tf.profile.ProfileOptionBuilder构建字典 </p>
<div class="hlcode"><pre><span class="k">class</span> <span class="nc">ProfileOptionBuilder</span><span class="err">：</span>
<span class="c"># 用于Profiling API的Option Builder。</span>
<span class="c"># 返回字典</span>
</pre></div>


<p>评估器选项构建器 ProfileOptionBuilder<br />
1. 记录内容选项<br />
2. 输出内容格式选项<br />
3. 限制节点选项</p>
<h4 id="141">1.4.1. 记录内容选项</h4>
<h5 id="1411">1.4.1.1. 记录时间和内存消耗</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">{})</span>

<span class="c"># 时间和内存消耗</span>
<span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">time_and_memory</span><span class="p">(</span>
    <span class="n">min_micros</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">min_bytes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">min_accelerator_micros</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_cpu_micros</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_peak_bytes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_residual_bytes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_output_bytes</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>


<h5 id="1412">1.4.1.2. 记录浮点运算情况</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">float_operation</span><span class="p">()</span>
</pre></div>


<h4 id="142">1.4.2. 输出选项</h4>
<p>输出文件格式<br />
1. time line : 输出JSON events file, 再用chrome浏览器tracing功能进行查看，可视性很棒。<br />
2. stdout ： 标准输出设备打印。<br />
3. pprof file: 输出pprof的文件格式，再用pprof工具查看。<br />
4. file: 输出到普通的文本文件。</p>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_pprof_output</span><span class="p">(</span><span class="n">pprof_file</span><span class="o">=</span><span class="s">&quot;./xxx.pb.gz.&quot;</span><span class="p">)</span> <span class="err">#</span> <span class="err">生成一个</span><span class="n">pprof</span> <span class="n">profile</span> <span class="n">gzip</span> <span class="n">file</span><span class="p">.</span>
<span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_stdout_output</span><span class="p">()</span> <span class="err">#</span> <span class="n">c</span><span class="o">++</span> <span class="n">std</span> <span class="n">out</span> <span class="n">Print</span> <span class="n">the</span> <span class="n">result</span> <span class="n">to</span> <span class="n">stdout</span><span class="p">.</span>
<span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_timeline_output</span><span class="p">(</span><span class="n">timeline_file</span><span class="o">=</span><span class="s">&quot;./xxx.json&quot;</span><span class="p">)</span> <span class="err">#生成一个</span><span class="n">json</span> <span class="err">文件</span>
<span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_file_output</span><span class="p">(</span><span class="n">outfile</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span> <span class="err">#输出一个文件</span>
<span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_empty_output</span><span class="p">()</span><span class="err">#不输出</span>

<span class="cp">#定义显示sess.Run() 第70步的统计数据,如果为-1，则使用所#有可用步骤的平均值。</span>
<span class="n">ProfileOptionBuilder</span><span class="p">.</span><span class="n">with_step</span><span class="p">(</span><span class="mi">70</span><span class="p">)</span>
</pre></div>


<h4 id="143">1.4.3. 限定选项</h4>
<h5 id="1431-profiler">1.4.3.1. 选择制定profiler节点</h5>
<div class="hlcode"><pre><span class="n">attributes</span><span class="o">=</span><span class="p">[]</span>
<span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">attributes</span><span class="p">)</span>
</pre></div>


<h5 id="1432-profiler">1.4.3.2. 选择消耗时间大于阈值的profiler节点</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">with_min_execution_time</span><span class="p">(</span>
    <span class="n">min_micros</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_accelerator_micros</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_cpu_micros</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>


<p>只显示消耗不少于“min_micros”的profiler节点。</p>
<h5 id="1433-profiler">1.4.3.3. 选择消耗空间大于阈值的profiler节点</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">with_min_memory</span><span class="p">(</span>
    <span class="n">min_bytes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_peak_bytes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_residual_bytes</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">min_output_bytes</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</pre></div>


<h5 id="1434-profiler">1.4.3.4. 选择运算大于阈值的profiler节点</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">with_min_float_operations</span><span class="p">(</span><span class="n">min_float_ops</span><span class="p">)</span>
</pre></div>


<h5 id="1435-profiler">1.4.3.5. 选择参数数量大于阈值的profiler节点</h5>
<div class="hlcode"><pre><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">with_min_parameters</span><span class="p">(</span><span class="n">min_params</span><span class="p">)</span>
</pre></div>


<p>仅显示不超过'min_params'参数的profiler节点。</p>
<h4 id="144-">1.4.4. 评估器选项构建器-构建</h4>
<div class="hlcode"><pre><span class="c">#构建profiling选项</span>
<span class="n">profile_opt_dict</span><span class="o">=</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
<span class="nb">type</span><span class="p">(</span><span class="n">profile_opt_dict</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span><span class="nb">dict</span> 
</pre></div>


<h4 id="145">1.4.5. 输出视图</h4>
<p>例子1：grpah view显示每个graph node运行时间，并输出到timeline<br />
例子2：scope view显示模型中的参数数量分布 <br />
例子4： code view – 显示python代码的执行资源消耗 </p>
<h3 id="15">1.5. 常用实例</h3>
<h4 id="151-flop">1.5.1. 浮点运算次数 flop</h4>
<div class="hlcode"><pre><span class="k">def</span> <span class="nf">get_flops</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
        <span class="n">run_meta</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>
        <span class="n">opts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">float_operation</span><span class="p">()</span>

        <span class="c"># We use the Keras session graph in the call to the profiler.</span>
        <span class="n">flop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
                                        <span class="n">run_meta</span><span class="o">=</span><span class="n">run_meta</span><span class="p">,</span> <span class="n">cmd</span><span class="o">=</span><span class="s">&#39;op&#39;</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">opts</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">flop</span><span class="o">.</span><span class="n">total_float_ops</span>  <span class="c"># Prints the &quot;flop&quot; of the model.</span>
</pre></div>


<h4 id="152">1.5.2. 总参数量</h4>
<div class="hlcode"><pre><span class="c">## 统计参数量</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">trainable_variables_parameter</span><span class="p">()</span>
<span class="n">param_stats</span> <span class="o">=</span> <span class="n">profiler</span><span class="o">.</span><span class="n">profile_name_scope</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="n">opts</span><span class="p">)</span>
<span class="c"># 总参数量</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;总参数：&#39;</span><span class="p">,</span> <span class="n">param_stats</span><span class="o">.</span><span class="n">total_parameters</span><span class="p">)</span>
<span class="c"># 各scope参数量</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">param_stats</span><span class="o">.</span><span class="n">children</span><span class="p">:</span>
  <span class="k">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="s">&#39;scope参数：&#39;</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">total_parameters</span><span class="p">)</span>
</pre></div>


<h4 id="153">1.5.3. 统计模型内存和耗时情况</h4>
<div class="hlcode"><pre><span class="n">builder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">builder</span><span class="p">(</span><span class="n">builder</span><span class="o">.</span><span class="n">time_and_memory</span><span class="p">())</span>
<span class="c">#opts.with_step(1)</span>
<span class="n">opts</span><span class="o">.</span><span class="n">with_timeline_output</span><span class="p">(</span><span class="s">&#39;timeline.json&#39;</span><span class="p">)</span>
<span class="n">opts</span> <span class="o">=</span> <span class="n">opts</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>

<span class="c">#profiler.profile_name_scope(opts) # 只能保存单step的timeline</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">profile_graph</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span> <span class="c"># 保存各个step的timeline</span>
</pre></div>


<h4 id="154-profile">1.5.4. 给出使用profile工具给出建议</h4>
<div class="hlcode"><pre><span class="n">opts</span> <span class="o">=</span> <span class="p">{</span><span class="s">&#39;AcceleratorUtilizationChecker&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s">&#39;ExpensiveOperationChecker&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s">&#39;JobChecker&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s">&#39;OperationChecker&#39;</span><span class="p">:</span> <span class="p">{}}</span>
<span class="n">profiler</span><span class="o">.</span><span class="n">advise</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>
</pre></div>


<h3 id="16-profile">1.6. 基于profile的建议</h3>
<p>不要每次　sess.run 里面都加入 runmetadata 对象，这样会使得整个模型每次都去收集时间耗费及内存占用数据，只需要隔N次收集一次就行了；</p>
<h3 id="17-estimatorprofile">1.7. 在estimator中使用profile</h3>
<div class="hlcode"><pre><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">tfprof</span><span class="o">.</span><span class="n">ProfileContext</span><span class="p">(</span><span class="s">&#39;/tmp/train_dir&#39;</span><span class="p">,</span> <span class="n">dump_steps</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">])</span> <span class="k">as</span> <span class="n">pctx</span><span class="p">:</span>
  <span class="n">estimator</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c"># any thing you want to profile</span>
</pre></div>


<p>在<code>/tmp/train_dir</code> 中就会得到<code>profile_10</code> 文件 </p>
<h3 id="18-keras">1.8. 在keras 中使用</h3>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.client</span> <span class="kn">import</span> <span class="n">timeline</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="n">run_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="p">(</span><span class="n">trace_level</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">RunOptions</span><span class="o">.</span><span class="n">FULL_TRACE</span><span class="p">)</span>
<span class="n">run_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">RunMetadata</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="o">...</span>  <span class="c"># A Keras model</span>

<span class="n">fn</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">run_options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">run_metadata</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="n">fn</span><span class="p">([</span><span class="n">x</span><span class="p">])</span>
    <span class="n">tl</span> <span class="o">=</span> <span class="n">timeline</span><span class="o">.</span><span class="n">Timeline</span><span class="p">(</span><span class="n">run_metadata</span><span class="o">.</span><span class="n">step_stats</span><span class="p">)</span>
    <span class="n">ctf</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">generate_chrome_trace_format</span><span class="p">()</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;timeline_</span><span class="si">%d</span><span class="s">.json&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="s">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ctf</span><span class="p">)</span>
</pre></div>


<p>Case 2</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="k">def</span> <span class="nf">stats_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">):</span>
    <span class="n">flops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">float_operation</span><span class="p">())</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">ProfileOptionBuilder</span><span class="o">.</span><span class="n">trainable_variables_parameter</span><span class="p">())</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&#39;FLOPs: {};    Trainable params: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">flops</span><span class="o">.</span><span class="n">total_float_ops</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">total_parameters</span><span class="p">))</span>



<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.initializers</span> <span class="kn">import</span> <span class="n">Constant</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">bias_initializer</span><span class="o">=</span><span class="n">Constant</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">Constant</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span>
<span class="n">stats_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
</pre></div>


<h1 id="2">2. 工具</h1>
<h2 id="21-tensorflow-profiler-ui">2.1. Tensorflow Profiler UI</h2>
<p>参考资料<sup id="fnref:1"><a class="footnote-ref" href="#fn:1" rel="footnote">1</a></sup></p>
<h3 id="211-installation">2.1.1. 安装 Installation</h3>
<ol>
<li>下载文件 profiler-ui 的源文件</li>
</ol>
<div class="hlcode"><pre><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="o">:</span><span class="c1">//github.com/tensorflow/profiler-ui.git</span>
</pre></div>


<p>1.Install Python dependencies. </p>
<div class="hlcode"><pre><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="p">.</span><span class="n">txt</span>
</pre></div>


<p>2.Install pprof.</p>
<p>[1] 下载 安装go语言包 </p>
<p>安装包下载地址为：https://golang.org/dl/。<br />
如果打不开可以使用这个地址：https://golang.google.cn/dl/</p>
<p>参考：https://www.runoob.com/go/go-environment.html</p>
<p>装 pprof 的时候会有个坑点，CentOS 库中可以找到 gperftools 这个工具，也是 Google 提供的，yum 装上之后可执行文件的名字也叫 pprof ！！但是跟这里用到的 pprof 不是一个玩意！！</p>
<p>[2] 安装pprof</p>
<div class="hlcode"><pre><span class="k">go</span> <span class="nx">get</span> <span class="o">-</span><span class="nx">u</span> <span class="nx">github</span><span class="p">.</span><span class="nx">com</span><span class="o">/</span><span class="nx">google</span><span class="o">/</span><span class="nx">pprof</span>
</pre></div>


<h3 id="212-profiler">2.1.2. 准备 profiler 文件</h3>
<p>3.Create a profile context file using the tf.contrib.tfprof.ProfileContext class. </p>
<p>生成持久化文件 <code>/path/to/your/profile.context</code></p>
<h3 id="213-ui">2.1.3. 启动 UI</h3>
<p>进入到  profiler-ui 的文件夹下 </p>
<div class="hlcode"><pre><span class="n">python</span> <span class="n">ui</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">profile_context_path</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">your</span><span class="o">/</span><span class="n">profile</span><span class="o">.</span><span class="n">context</span>
</pre></div>


<h1 id="3-2">3. 优化策略<sup id="fnref:2"><a class="footnote-ref" href="#fn:2" rel="footnote">2</a></sup></h1>
<h2 id="31">3.1. 硬件</h2>
<h3 id="311">3.1.1. 单机</h3>
<h4 id="3111-cpu">3.1.1.1. CPU 加速</h4>
<h4 id="3112-gpu">3.1.1.2. GPU 加速</h4>
<h4 id="3113-tpu">3.1.1.3. TPU 加速</h4>
<h4 id="3114-io">3.1.1.4. I/O 开销</h4>
<h3 id="312">3.1.2. 集群</h3>
<h2 id="32-jit">3.2. JIT 编译</h2>
<p>使用即时编译<br />
注意: 为了支持 XLA（加速线性代数），TensorFlow 必须从源文件编译。</p>
<p>为什么使用即时编译？<br />
TensorFlow / XLA 即时编译器通过 XLA 编译和运行 TensorFlow 图的各个部分。与标准的 TensorFlow 实现相比，XLA 的好处是可以将多个运算符（内核融合）融合到少量的编译内核中。与 TensorFlow 逐个运行操作相比，融合运算能减少对<strong>内存带宽</strong>的要求，同时提升性能。</p>
<p>通过 XLA 运行 TensorFlow 图<br />
有两种方式通过 XLA 运行 TensorFlow 计算图：一是用 CPU 或 GPU 设备上的即时编译操作，二是把操作放到 XLA_CPU 或 XLA_GPU TensorFlow 设备上。将操作直接放到一个 TensorFlow XLA<br />
设备上强制执行，因此这种方法主要用于测试。</p>
<p>注意：XLA CPU 后端会生成快速、单线程的代码，但是不会如 TensorFlow CPU 后端一样并行化。 XLA GPU 后端与标准的 TensorFlow 后端充分竞争，运行速度时快时慢。</p>
<p>开启即时编译<br />
即时编译可以在会话层开启，或手动进行选择操作。两种方式都是零拷贝 --- 数据在同台设备的已编译 XLA 内核和 TensorFlow 操作之间传递时，无需另行复制。</p>
<p>会话<br />
在会话层开启即时编译时，系统将尽可能把所有操作编译成 XLA 计算。每个 XLA 计算将被编译成单个或多个设备底层内核。</p>
<p>受某些限制影响，如果图模型中有两个相邻的操作都要使用 XLA，它们将会被编译成单个 XLA 计算。</p>
<p>通过将 global_jit_level 设置成tf.OptimizerOptions.ON_1，并在会话初始化阶段传入配置，就可以在会话层开启即时编译。</p>
<h1 id="4">4. 配置开启即时编译</h1>
<p>config = tf.ConfigProto()<br />
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1</p>
<p>sess = tf.Session(config=config)<br />
注意：在会话层开启即时编译将不会导致为 CPU 编译操作。CPU 运算的即时编译必须通过下面描述的手动方法开启，原因在于 CPU 后端是单线程的。</p>
<p>手动开启<br />
对于单个或多个操作，可以手动开启即时编译，通过对运算进行标记以使用属性 _XlaCompile=true 来进行编译。最简单的方法就是通过在 tensorflow/contrib/compiler/jit.py<br />
中定义的 tf.contrib.compiler.jit.experimental_jit_scope() 。<br />
使用范例：</p>
<div class="hlcode"><pre><span class="n">jit_scope</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">contrib</span><span class="p">.</span><span class="n">compiler</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">experimental_jit_scope</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">with</span> <span class="n">jit_scope</span><span class="p">()</span><span class="o">:</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>  <span class="err">#</span> <span class="n">add</span> <span class="err">将被</span> <span class="n">XLA</span> <span class="err">编译</span>
</pre></div>


<p>_XlaCompile 属性目前是以最佳的方式支持的。如果一个操作无法编译，TensorFlow 将默认回退到常规实现。</p>
<p>将操作加载到 XLA 设备中<br />
通过 XLA 执行计算的另一种方法是将操作载入到特定的 XLA 设备上。这个方法通常只用于测试。有效设备包括 XLA_CPU 或 XLA_GPU。</p>
<p>with tf.device("/job:localhost/replica:0/task:0/device:XLA_GPU:0"):<br />
  output = tf.add(input1, input2)<br />
不同于标准 CPU 和 GPU 设备上的即时编译，这些设备在传输到设备上和关闭设备时，会生成一个数据副本。额外的拷贝导致在同一个图模型中混合使用 XLA 和 TensorFlow 操作的开销变得很大。</p>
<p>教程<br />
这个教程涵盖了一个简单版的 MNIST softmax 训练模型。在会话层开启了即时编译，只支持 GPU。</p>
<p>在开始本教程之前，先验证 LD_LIBRARY 环境变量或者 ldconfig 包含 $CUDA_ROOT/extras/CUPTI/lib64，其中包含 CUDA 分析工具接口库<br />
(CUPTI)。TensorFlow 使用 CUPTI 从 GPU 获取追踪信息。</p>
<p>步骤 #1: 准备代码范例<br />
下载或移动 mnist_softmax_xla.py 到 TensorFlow 源码之外的文件夹中。</p>
<p>步骤 #2: 无 XLA 运行<br />
执行 python 代码，不用 XLA 训练模型。</p>
<p>python mnist_softmax_xla.py --xla=''<br />
使用 Chrome 跟踪事件探查器 (导航到 chrome://tracing)，当代码执行完时打开时间线文件 timeline.ctf.json。呈现的时间线类似于下图，其中有多个绿色框，标记为 MatMul，可能跨多个 GPU 。</p>
<p>步骤 #3：用 XLA 运行代码<br />
执行 python 代码，用 XLA 训练模型，并打开 XLA 调试工具，用环境变量输出 XLA 图。</p>
<p>TF_XLA_FLAGS=--xla_generate_hlo_graph=.* python mnist_softmax_xla.py<br />
打开时间线文件(timeline.ctf.json)。呈现的时间线类似于下图，其中有一个标有 _XlaLaunch<br />
的长块。</p>
<p>通过查看控制台类似下面的输出来了解在 _XlaLaunch 里到底发生了什么:</p>
<p>computation cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=1].v82 [CPU:<br />
pipeline start, before inline]: /tmp/hlo_graph_0.dot<br />
控制台显示了包含 XLA 创建的图模型信息的 hlo_graph_xx.dot 文件位置。XLA 融合操作的过程可以从 hlo_graph_0.dot 开始逐个查看分析图了解。</p>
<p>为了将 .dot 文件渲染成 png 格式，需安装 GraphViz 并运行:</p>
<p>dot -Tpng hlo_graph_80.dot -o hlo_graph_80.png<br />
结果如下图：</p>
<h1 id="5">5. 参考资料</h1>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>profiler-ui Github pages https://github.com/tensorflow/profiler-ui&#160;<a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>美团基于TensorFlow Serving的深度学习在线预估 https://tech.meituan.com/2018/10/11/tfserving-improve.html&#160;<a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>Performance Analysis of Just-in-Time Compilation<br />
for Training TensorFlow Multi-Layer Perceptrons&#160;<a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
</ol>
</div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2021 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>