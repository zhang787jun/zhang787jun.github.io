<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>采样 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Science\Algorithm\机器学习基础">Data_Science\Algorithm\机器学习基础</a>&nbsp;»&nbsp;采样</div>
</div>
<div class="clearfix"></div>
<div id="title">采样</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 不平衡的数据集</a><ul>
<li><a href="#11">1.1. 评价指标陷阱</a></li>
<li><a href="#12">1.2. 改善的评估指标</a><ul>
<li><a href="#121-confusion-matrix">1.2.1. Confusion matrix</a></li>
<li><a href="#122-normalized-gini-coefficient">1.2.2. Normalized Gini Coefficient</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2">2. 重采样</a><ul>
<li><a href="#21">2.1. 欠采样</a><ul>
<li><a href="#211">2.1.1. 随机欠采样</a></li>
<li><a href="#212-easyensemble">2.1.2. EasyEnsemble （周志华）</a></li>
<li><a href="#213-tomek-links">2.1.3. Tomek links</a></li>
<li><a href="#214-clustercentroids">2.1.4. ClusterCentroids</a></li>
</ul>
</li>
<li><a href="#22">2.2. 过采样</a><ul>
<li><a href="#221">2.2.1. 随机过采样</a></li>
<li><a href="#222-smote">2.2.2. SMOTE 算法</a><ul>
<li><a href="#2221">2.2.2.1. 改进</a></li>
<li><a href="#2222">2.2.2.2. 实践</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#3">3. 参考资料</a></li>
</ul>
</div>
<h1 id="1">1. 不平衡的数据集</h1>
<p>像金融欺诈等 数据集为典型的不平衡的数据集</p>
<h2 id="11">1.1. 评价指标陷阱</h2>
<p>正确率、准确率等对于不平衡数据集存在陷阱</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="c"># Remove &#39;id&#39; and &#39;target&#39; columns</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">labels</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s">&#39;target&#39;</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Accuracy: </span><span class="si">%.2f%%</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">96.36</span><span class="o">%</span>
</pre></div>


<div class="hlcode"><pre><span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">[[</span><span class="s">&#39;ps_calc_01&#39;</span><span class="p">]],</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[[</span><span class="s">&#39;ps_calc_01&#39;</span><span class="p">]])</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Accuracy: </span><span class="si">%.2f%%</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">accuracy</span> <span class="o">*</span> <span class="mf">100.0</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">Accuracy</span><span class="p">:</span> <span class="mf">96.36</span><span class="o">%</span>
</pre></div>


<h2 id="12">1.2. 改善的评估指标</h2>
<ol>
<li>使用<strong>混合矩阵</strong>评估结果 </li>
<li>使用归一化的基尼系数评估<br />
    &gt; 0 for random guessing,<br />
    &gt; to approximately 0.5 for a perfect score.</li>
</ol>
<h3 id="121-confusion-matrix">1.2.1. Confusion matrix</h3>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">conf_mat</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Confusion matrix:</span><span class="se">\n</span><span class="s">&#39;</span><span class="p">,</span> <span class="n">conf_mat</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s">&#39;Class 1&#39;</span><span class="p">]</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">cax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">conf_mat</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Blues</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">cax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s">&#39;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">&#39;Expected&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">Confusion</span> <span class="n">matrix</span><span class="p">:</span>
 <span class="p">[[</span><span class="mi">114709</span>      <span class="mi">0</span><span class="p">]</span>
 <span class="p">[</span>  <span class="mi">4334</span>      <span class="mi">0</span><span class="p">]]</span>
</pre></div>


<h3 id="122-normalized-gini-coefficient">1.2.2. Normalized Gini Coefficient</h3>
<h1 id="2">2. 重采样</h1>
<ul>
<li>通过对数据集采样降低时间复杂度</li>
<li>过采样/欠采样 解决数分布不均的问题class-imbalance</li>
</ul>
<h2 id="21">2.1. 欠采样</h2>
<h3 id="211">2.1.1. 随机欠采样</h3>
<div class="hlcode"><pre><span class="c"># 2. Class count</span>
<span class="n">count_class_0</span><span class="p">,</span> <span class="n">count_class_1</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
<span class="c"># 3. Divide by class</span>
<span class="n">df_class_0</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">[</span><span class="s">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">df_class_1</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="p">[</span><span class="s">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">Random</span> <span class="n">under</span><span class="o">-</span><span class="n">sampling</span>
<span class="n">In</span> <span class="p">[</span><span class="mi">6</span><span class="p">]:</span>
<span class="n">df_class_0_under</span> <span class="o">=</span> <span class="n">df_class_0</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">count_class_1</span><span class="p">)</span>
<span class="n">df_test_under</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_class_0_under</span><span class="p">,</span> <span class="n">df_class_1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Random under-sampling:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df_test_under</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">df_test_under</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">&#39;bar&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Count (target)</span>

<span class="o">&gt;&gt;&gt;</span>
<span class="n">Random</span> <span class="n">under</span><span class="o">-</span><span class="n">sampling</span><span class="p">:</span>
<span class="mi">1</span>    <span class="mi">21694</span>
<span class="mi">0</span>    <span class="mi">21694</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>


<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>
<span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">return_indices</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_rus</span><span class="p">,</span> <span class="n">y_rus</span><span class="p">,</span> <span class="n">id_rus</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Removed indexes:&#39;</span><span class="p">,</span> <span class="n">id_rus</span><span class="p">)</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_rus</span><span class="p">,</span> <span class="n">y_rus</span><span class="p">,</span> <span class="s">&#39;Random under-sampling&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">Removed</span> <span class="n">indexes</span><span class="p">:</span> <span class="p">[</span><span class="mi">51</span> <span class="mi">94</span> <span class="mi">73</span>  <span class="mi">3</span> <span class="mi">48</span> <span class="mi">81</span> <span class="mi">20</span> <span class="mi">10</span> <span class="mi">29</span> <span class="mi">85</span>  <span class="mi">4</span>  <span class="mi">8</span>  <span class="mi">9</span> <span class="mi">14</span> <span class="mi">16</span> <span class="mi">40</span> <span class="mi">67</span> <span class="mi">70</span> <span class="mi">71</span> <span class="mi">74</span><span class="p">]</span>
</pre></div>


<h3 id="212-easyensemble">2.1.2. EasyEnsemble （周志华）</h3>
<p>https://imbalanced-learn.org/en/stable/generated/imblearn.ensemble.EasyEnsemble.html</p>
<h3 id="213-tomek-links">2.1.3. Tomek links</h3>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">TomekLinks</span>
<span class="n">tl</span> <span class="o">=</span> <span class="n">TomekLinks</span><span class="p">(</span><span class="n">return_indices</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="s">&#39;majority&#39;</span><span class="p">)</span>
<span class="n">X_tl</span><span class="p">,</span> <span class="n">y_tl</span><span class="p">,</span> <span class="n">id_tl</span> <span class="o">=</span> <span class="n">tl</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Removed indexes:&#39;</span><span class="p">,</span> <span class="n">id_tl</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">Removed</span> <span class="n">indexes</span><span class="p">:</span> <span class="p">[</span> <span class="mi">0</span>  <span class="mi">1</span>  <span class="mi">2</span>  <span class="mi">4</span>  <span class="mi">5</span>  <span class="mi">6</span>  <span class="mi">7</span>  <span class="mi">8</span>  <span class="mi">9</span> <span class="mi">10</span> <span class="mi">11</span> <span class="mi">12</span> <span class="mi">13</span> <span class="mi">14</span> <span class="mi">15</span> <span class="mi">16</span> <span class="mi">17</span> <span class="mi">18</span> <span class="mi">19</span> <span class="mi">20</span> <span class="mi">21</span> <span class="mi">22</span> <span class="mi">23</span> <span class="mi">24</span> <span class="mi">25</span>
 <span class="mi">26</span> <span class="mi">27</span> <span class="mi">28</span> <span class="mi">29</span> <span class="mi">30</span> <span class="mi">31</span> <span class="mi">32</span> <span class="mi">34</span> <span class="mi">35</span> <span class="mi">36</span> <span class="mi">37</span> <span class="mi">38</span> <span class="mi">39</span> <span class="mi">40</span> <span class="mi">41</span> <span class="mi">42</span> <span class="mi">43</span> <span class="mi">44</span> <span class="mi">45</span> <span class="mi">46</span> <span class="mi">47</span> <span class="mi">48</span> <span class="mi">49</span> <span class="mi">50</span> <span class="mi">51</span>
 <span class="mi">52</span> <span class="mi">53</span> <span class="mi">54</span> <span class="mi">55</span> <span class="mi">56</span> <span class="mi">57</span> <span class="mi">58</span> <span class="mi">59</span> <span class="mi">60</span> <span class="mi">61</span> <span class="mi">62</span> <span class="mi">63</span> <span class="mi">64</span> <span class="mi">65</span> <span class="mi">66</span> <span class="mi">67</span> <span class="mi">68</span> <span class="mi">69</span> <span class="mi">70</span> <span class="mi">71</span> <span class="mi">72</span> <span class="mi">73</span> <span class="mi">74</span> <span class="mi">75</span> <span class="mi">76</span>
 <span class="mi">77</span> <span class="mi">78</span> <span class="mi">79</span> <span class="mi">80</span> <span class="mi">81</span> <span class="mi">82</span> <span class="mi">83</span> <span class="mi">84</span> <span class="mi">85</span> <span class="mi">86</span> <span class="mi">87</span> <span class="mi">88</span> <span class="mi">90</span> <span class="mi">91</span> <span class="mi">92</span> <span class="mi">93</span> <span class="mi">94</span> <span class="mi">95</span> <span class="mi">97</span> <span class="mi">98</span> <span class="mi">99</span><span class="p">]</span>
</pre></div>


<h3 id="214-clustercentroids">2.1.4. ClusterCentroids</h3>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">ClusterCentroids</span>
<span class="n">cc</span> <span class="o">=</span> <span class="n">ClusterCentroids</span><span class="p">(</span><span class="n">ratio</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">10</span><span class="p">})</span>
<span class="n">X_cc</span><span class="p">,</span> <span class="n">y_cc</span> <span class="o">=</span> <span class="n">cc</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_cc</span><span class="p">,</span> <span class="n">y_cc</span><span class="p">,</span> <span class="s">&#39;Cluster Centroids under-sampling&#39;</span><span class="p">)</span>
</pre></div>


<h2 id="22">2.2. 过采样</h2>
<h3 id="221">2.2.1. 随机过采样</h3>
<div class="hlcode"><pre><span class="n">df_class_1_over</span> <span class="o">=</span> <span class="n">df_class_1</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">count_class_0</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df_test_over</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_class_0</span><span class="p">,</span> <span class="n">df_class_1_over</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&#39;Random over-sampling:&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">df_test_over</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="n">df_test_over</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">&#39;bar&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">&#39;Count (target)&#39;</span><span class="p">);</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">Random</span> <span class="n">over</span><span class="o">-</span><span class="n">sampling</span><span class="p">:</span>
<span class="mi">1</span>    <span class="mi">573518</span>
<span class="mi">0</span>    <span class="mi">573518</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">int64</span>
</pre></div>


<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>
<span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">()</span>
<span class="n">X_ros</span><span class="p">,</span> <span class="n">y_ros</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_ros</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">&#39;new random picked points&#39;</span><span class="p">)</span>
</pre></div>


<h3 id="222-smote">2.2.2. SMOTE 算法</h3>
<p>参考:https://arxiv.org/abs/1106.1813<br />
https://www.jianshu.com/p/13fc0f7f5565</p>
<p>JAIR'2002的文章<code>《SMOTE: Synthetic Minority Over-sampling Technique》</code>提出了一种过采样算法SMOTE</p>
<p>本算法基于“插值”来为少数类合成新的样本。下面介绍如何合成新的样本。</p>
<p>设训练集的一个少数类的样本数为 T ，那么SMOTE算法将为这个少数类合成 NT 个新样本。这里要求 N 必须是正整数，如果给定的 N&lt;1 那么算法将“认为”少数类的样本数 $T=NT$ ，并将强制 $N=1$ 。</p>
<p>考虑该少数类的一个样本 i ，其特征向量为 $xi,i∈{1,...,T}$ ：</p>
<ol>
<li>
<p>首先从该少数类的全部 T 个样本中找到样本 xi 的 k 个近邻（例如用欧氏距离），记为 xi(near),near∈{1,...,k} ；</p>
</li>
<li>
<p>然后从这 k 个近邻中随机选择一个样本 xi(nn) ，再生成一个 0 到 1 之间的随机数 ζ1 ，从而合成一个新样本 xi1 ：</p>
</li>
</ol>
<p>$$xi1=xi+ζ1⋅(xi(nn)−xi)$$</p>
<ol>
<li>将步骤2重复进行 N 次，从而可以合成 N 个新样本：xinew,new∈1,...,N。</li>
</ol>
<p>那么，对全部的 T 个少数类样本进行上述操作，便可为该少数类合成 NT 个新样本。</p>
<p>如果样本的特征维数是 2 维，那么每个样本都可以用二维平面上的一个点来表示。SMOTE算法所合成出的一个新样本 xi1 相当于是表示样本 xi 的点和表示样本 xi(nn) 的点之间所连线段上的一个点。所以说该算法是基于“插值”来合成新样本。</p>
<p><strong>SMOTE算法的缺陷</strong><br />
1. 是在近邻选择时,存在一定的盲目性。从上面的算法流程可以看出,在算法执行过程中,需要确定K值,即选择多少个近邻样本,这需要用户自行解决。从K值的定义可以看出,K值的下限是M值(M值为从K个近邻中随机挑选出的近邻样本的个数,且有M&lt; K),M的大小可以根据负类样本数量、正类样本数量和数据集最后需要达到的平衡率决定。但K值的上限没有办法确定,只能根据具体的数据集去反复测试。因此如何确定K值,才能使算法达到最优这是未知的。<br />
2. 另外,该算法无法克服非平衡数据集的数据分布问题,容易产生分布边缘化问题。由于负类样本的分布决定了其可选择的近邻,如果一个负类样本处在负类样本集的分布边缘,则由此负类样本和相邻样本产生的“人造”样本也会处在这个边缘,且会越来越边缘化,从而模糊了正类样本和负类样本的边界,而且使边界变得越来越模糊。这种边界模糊性,虽然使数据集的平衡性得到了改善,但加大了分类算法进行分类的难度．</p>
<h4 id="2221">2.2.2.1. 改进</h4>
<p>针对SMOTE算法的进一步改进针对SMOTE算法存在的边缘化和盲目性等问题,很多人纷纷提出了新的改进办法,在一定程度上改进了算法的性能,但还存在许多需要解决的问题。</p>
<ol>
<li>Han等人Borderline-SMOTE: A New Over-Sampling Method in Imbalanced Data Sets Learning在SMOTE算法基础上进行了改进,提出了Borderhne.SMOTE算法,解决了生成样本重叠(Overlapping)的问题该算法在运行的过程中,查找一个适当的区域,该区域可以较好地反应数据集的性质,然后在该区域内进行插值,以使新增加的“人造”样本更有效。这个适当的区域一般由经验给定,因此算法在执行的过程中有一定的局限性。</li>
</ol>
<p>Over-sampling followed by under-sampling<br />
Now, we will do a combination of over-sampling and under-sampling, using the SMOTE and Tomek links techniques:<br />
In [17]:</p>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.combine</span> <span class="kn">import</span> <span class="n">SMOTETomek</span>
<span class="n">smt</span> <span class="o">=</span> <span class="n">SMOTETomek</span><span class="p">(</span><span class="n">ratio</span><span class="o">=</span><span class="s">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">X_smt</span><span class="p">,</span> <span class="n">y_smt</span> <span class="o">=</span> <span class="n">smt</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_smt</span><span class="p">,</span> <span class="n">y_smt</span><span class="p">,</span> <span class="s">&#39;SMOTE + Tomek links&#39;</span><span class="p">)</span>
</pre></div>


<h4 id="2222">2.2.2.2. 实践</h4>
<div class="hlcode"><pre><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="n">smote</span> <span class="o">=</span> <span class="n">SMOTE</span><span class="p">(</span><span class="n">ratio</span><span class="o">=</span><span class="s">&#39;minority&#39;</span><span class="p">)</span>

<span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span> <span class="o">=</span> <span class="n">smote</span><span class="o">.</span><span class="n">fit_sample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plot_2d_space</span><span class="p">(</span><span class="n">X_sm</span><span class="p">,</span> <span class="n">y_sm</span><span class="p">,</span> <span class="s">&#39;SMOTE over-sampling&#39;</span><span class="p">)</span>
</pre></div>


<h1 id="3">3. 参考资料</h1>
<ol>
<li>
<p>The imbalanced-learn documentation:<br />
http://contrib.scikit-learn.org/imbalanced-learn/stable/index.html</p>
</li>
<li>
<p>The imbalanced-learn GitHub:<br />
https://github.com/scikit-learn-contrib/imbalanced-learn</p>
</li>
<li>
<p>Comparison of the combination of over- and under-sampling algorithms:<br />
http://contrib.scikit-learn.org/imbalanced-learn/stable/auto_examples/combine/plot_comparison_combine.html</p>
</li>
<li>
<p>Chawla, Nitesh V., et al. "SMOTE: synthetic minority over-sampling technique." Journal of artificial intelligence research 16 (2002):<br />
https://www.jair.org/media/953/live-953-2037-jair.pdf</p>
</li>
<li>
<p>Haibo He, Edwardo A. Garcia的Learning from Imbalanced Data[<strong>重点推荐</strong>]</p>
</li>
</ol>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2020 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>