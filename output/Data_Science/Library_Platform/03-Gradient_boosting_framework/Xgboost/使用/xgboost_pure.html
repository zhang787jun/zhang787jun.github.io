<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>xgboost--原生API使用 - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Data_Science\Library_Platform\03-Gradient_boosting_framework\Xgboost\使用">Data_Science\Library_Platform\03-Gradient_boosting_framework\Xgboost\使用</a>&nbsp;»&nbsp;xgboost--原生API使用</div>
</div>
<div class="clearfix"></div>
<div id="title">xgboost--原生API使用</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#1">1. 实践</a><ul>
<li><a href="#11">1.1. 创建数据对象</a></li>
<li><a href="#12">1.2. 设置参数</a></li>
<li><a href="#13">1.3. 训练</a><ul>
<li><a href="#131">1.3.1. 通用模式</a></li>
<li><a href="#132">1.3.2. 早停模式</a></li>
</ul>
</li>
<li><a href="#14">1.4. 模型评估</a></li>
<li><a href="#15">1.5. 模型保存</a></li>
<li><a href="#16">1.6. 加载模型</a></li>
<li><a href="#17">1.7. 预测</a></li>
<li><a href="#18">1.8. 绘图</a></li>
<li><a href="#19-gpu">1.9. GPU 加速</a></li>
<li><a href="#110">1.10. 特征重要性</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="1">1. 实践</h1>
<h2 id="11">1.1. 创建数据对象</h2>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>
<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">train_file</span><span class="p">)</span>
<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="n">df_label</span><span class="p">)</span>

<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">&#39;train.svm.txt&#39;</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">&#39;test.svm.buffer&#39;</span><span class="p">)</span>

<span class="n">dtrain</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="s">&#39;train.csv?format=csv&amp;label_column=0&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">sys</span> 
<span class="n">sys</span><span class="o">.</span><span class="n">getsizeof</span><span class="p">(</span><span class="n">dtrain</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="mi">55</span> <span class="c"># 占用内存大小55 bytpe</span>
<span class="c"># dtrain 是一个对象，没有加载数据,</span>
</pre></div>


<h2 id="12">1.2. 设置参数</h2>
<p>参数通过字典的形式传达到训练器中 </p>
<div class="hlcode"><pre><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">&quot;booster&quot;</span><span class="p">:</span><span class="s">&quot;gbtree&quot;</span><span class="p">,</span> <span class="s">&quot;verbosity：1&quot;</span><span class="p">,</span><span class="s">&#39;max_depth&#39;</span><span class="p">:</span><span class="mi">6</span><span class="p">,</span> <span class="s">&#39;eta&#39;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">,</span> <span class="s">&quot;gamma&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="s">&quot;subsample&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">&quot;tree_method&quot;</span><span class="p">:</span><span class="s">&quot;hist&quot;</span><span class="p">,</span><span class="s">&quot;lambda&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span><span class="s">&quot;alpha&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
<span class="s">&#39;objective&#39;</span><span class="p">:</span><span class="s">&#39;binary:logistic&#39;</span><span class="p">,</span><span class="s">&quot;subsample&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="p">}</span>
<span class="n">num_round</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>


<h2 id="13">1.3. 训练</h2>
<h3 id="131">1.3.1. 通用模式</h3>
<div class="hlcode"><pre><span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,)</span>
</pre></div>


<h3 id="132">1.3.2. 早停模式</h3>
<p>如果您有一个验证集, 你可以使用提前停止找到最佳数量的 boosting rounds（梯度次数）. 提前停止至少需要一个 evals 集合. 如果有多个, 它将使用最后一个.</p>
<div class="hlcode"><pre><span class="n">xgb</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">evals</span><span class="o">=</span><span class="n">evals</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>


<p>该模型将开始训练, 直到验证得分停止提高为止. 验证错误需要至少每个 early_stopping_rounds 减少以继续训练.</p>
<p>如果提前停止，模型将有三个额外的字段: bst.best_score, bst.best_iteration 和 bst.best_ntree_limit. 请注意 train() 将从上一次迭代中返回一个模型, 而不是最好的一个.</p>
<p>这与两个度量标准一起使用以达到最小化（RMSE, 对数损失等）和最大化（MAP, NDCG, AUC）. 请注意, 如果您指定多个评估指标, 则 param ['eval_metric'] 中的最后一个用于提前停止.<br />
预测</p>
<p>当您 训练/加载 一个模型并且准备好数据之后, 即可以开始做预测了.</p>
<div class="hlcode"><pre><span class="c"># 7 个样本, 每一个包含 10 个特征</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">dtest</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">DMatrix</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">bst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xgmat</span><span class="p">)</span>
</pre></div>


<p>如果在训练过程中提前停止, 可以用 bst.best_ntree_limit 从最佳迭代中获得预测结果:</p>
<div class="hlcode"><pre><span class="n">ypred</span> <span class="o">=</span> <span class="n">bst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xgmat</span><span class="p">,</span><span class="n">ntree_limit</span><span class="o">=</span><span class="n">bst</span><span class="o">.</span><span class="n">best_ntree_limit</span><span class="p">)</span>
</pre></div>


<h2 id="14">1.4. 模型评估</h2>
<ol>
<li>在 param 字典中添加<eval_metric:value_list></li>
<li>value_list 中 可选项为 <code>rmse</code>,<code>error</code>,<code>auc</code></li>
<li>添加 watchlist</li>
<li>定义空的evals_result，并传入到xgb.train 中间</li>
</ol>
<div class="hlcode"><pre><span class="cp"># 在 param 中添加eval_metric</span>
<span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="err">&#39;</span><span class="n">bst</span><span class="o">:</span><span class="n">max_depth</span><span class="err">&#39;</span><span class="o">:</span> <span class="mi">2</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">bst</span><span class="o">:</span><span class="n">eta</span><span class="err">&#39;</span><span class="o">:</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="err">&#39;</span><span class="n">silent</span><span class="err">&#39;</span><span class="o">:</span> <span class="mi">1</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">objective</span><span class="err">&#39;</span><span class="o">:</span> <span class="err">&#39;</span><span class="n">binary</span><span class="o">:</span><span class="n">logistic</span><span class="err">&#39;</span><span class="p">,</span> <span class="err">&#39;</span><span class="n">eval_metric</span><span class="err">&#39;</span><span class="o">:</span> <span class="p">[</span><span class="err">&#39;</span><span class="n">error</span><span class="err">&#39;</span><span class="p">,</span> <span class="s">&quot;auc&quot;</span><span class="p">]}</span>
<span class="n">num_round</span> <span class="o">=</span> <span class="mi">2</span>
<span class="cp"># 添加 watchlist</span>
<span class="n">watchlist</span> <span class="o">=</span> <span class="p">[(</span><span class="n">dtest</span><span class="p">,</span><span class="err">&#39;</span><span class="n">eval</span><span class="err">&#39;</span><span class="p">),</span> <span class="p">(</span><span class="n">dtrain</span><span class="p">,</span><span class="err">&#39;</span><span class="n">train</span><span class="err">&#39;</span><span class="p">)]</span>
<span class="cp"># 定义空的evals_result，并传入到xgb.train 中间</span>
<span class="n">evals_result</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">dtrain</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,</span> <span class="n">watchlist</span><span class="p">,</span> <span class="n">evals_result</span><span class="o">=</span><span class="n">evals_result</span><span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="n">evals_result</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="p">{</span><span class="err">&#39;</span><span class="n">watchlist</span><span class="err">中的</span><span class="n">name</span><span class="err">&#39;</span><span class="o">:</span> <span class="p">{</span><span class="err">&#39;</span><span class="n">eval_metric</span> <span class="err">中的类型&#39;</span><span class="o">:</span> <span class="p">[</span><span class="mf">0.151299</span><span class="p">,</span> <span class="mf">0.150435</span><span class="p">,</span> <span class="mf">0.150391</span><span class="p">,</span> <span class="mf">0.150028</span><span class="p">,</span> <span class="mf">0.149955</span><span class="p">,</span> <span class="mf">0.150004</span><span class="p">,</span> <span class="mf">0.149852</span><span class="p">,</span> <span class="mf">0.149685</span><span class="p">,</span> <span class="mf">0.149008</span><span class="p">,</span> <span class="mf">0.148895</span><span class="p">],</span> <span class="err">&#39;</span><span class="n">auc</span><span class="err">&#39;</span><span class="o">:</span> <span class="p">[</span><span class="mf">0.719014</span><span class="p">,</span> <span class="mf">0.72576</span><span class="p">,</span> <span class="mf">0.73082</span><span class="p">,</span> <span class="mf">0.733395</span><span class="p">,</span> <span class="mf">0.738091</span><span class="p">,</span> <span class="mf">0.74203</span><span class="p">,</span> <span class="mf">0.745483</span><span class="p">,</span> <span class="mf">0.747434</span><span class="p">,</span> <span class="mf">0.750762</span><span class="p">,</span> <span class="mf">0.754281</span><span class="p">]}}</span>
</pre></div>


<h2 id="15">1.5. 模型保存</h2>
<p>训练之后，您可以保存模型并将其转储出去。</p>
<div class="hlcode"><pre><span class="n">bst</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">&#39;0001.model&#39;</span><span class="p">)</span>
</pre></div>


<p>转储模型和特征映射 您可以将模型转储到 txt 文件并查看模型的含义</p>
<div class="hlcode"><pre><span class="c"># 转存模型</span>
<span class="n">bst</span><span class="o">.</span><span class="n">dump_model</span><span class="p">(</span><span class="s">&#39;dump.raw.txt&#39;</span><span class="p">)</span>
<span class="c"># 转储模型和特征映射</span>
<span class="n">bst</span><span class="o">.</span><span class="n">dump_model</span><span class="p">(</span><span class="s">&#39;dump.raw.txt&#39;</span><span class="p">,</span><span class="s">&#39;featmap.txt&#39;</span><span class="p">)</span>
</pre></div>


<h2 id="16">1.6. 加载模型</h2>
<p>当您保存模型后, 您可以使用如下方式在任何时候加载模型文件</p>
<div class="hlcode"><pre><span class="n">bst</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">Booster</span><span class="p">({</span><span class="s">&#39;nthread&#39;</span><span class="p">:</span><span class="mi">4</span><span class="p">})</span> <span class="c">#init model</span>
<span class="n">bst</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s">&quot;model.bin&quot;</span><span class="p">)</span> <span class="c"># load data</span>
</pre></div>


<h2 id="17">1.7. 预测</h2>
<div class="hlcode"><pre><span class="n">ypred</span> <span class="o">=</span> <span class="n">bst</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dtest</span><span class="p">)</span>

<span class="nb">type</span><span class="p">(</span><span class="n">ypred</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">array</span> 
</pre></div>


<h2 id="18">1.8. 绘图</h2>
<p>xgb 的 plotting（绘图）模块可以绘制出 importance（重要性）以及输出的 tree（树）.<br />
前提：<br />
1. matplotlib<br />
2. graphviz</p>
<p>当您使用 IPython时, 你可以使用 to_graphviz 函数, 它可以将 target tree（目标树） 转换成 graphviz 实例. graphviz 实例会自动的在 IPython 上呈现.</p>
<div class="hlcode"><pre><span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>

<span class="n">xgb</span><span class="o">.</span><span class="n">plot_importance</span><span class="p">(</span><span class="n">bst</span><span class="p">)</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">bst</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c"># num_trees</span>

<span class="c"># 使用 IPython</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">to_graphviz</span><span class="p">(</span><span class="n">bst</span><span class="p">,</span> <span class="n">num_trees</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>


<h2 id="19-gpu">1.9. GPU 加速</h2>
<p>xgboost的GPU 加速只支持 英伟达 显卡的CUDA 上，且只有在 P100 之后的显卡才效率的有显著提高。对Pascal架构之前的显卡会使得计算变得更慢。</p>
<p>参考 ：https://xgboost.readthedocs.io/en/latest/gpu/index.html</p>
<p><strong>NOTE</strong><br />
Pascal架构作为 Maxwell 架构的升级版，2016 发布第一款产品 Tesla P100 (GP100) </p>
<h2 id="110">1.10. 特征重要性</h2>
<p>评价特征重要性的指标：</p>
<ol>
<li><code>weight</code><ul>
<li>在这个树集合模型中，用该特征进行决策树分割的总次数</li>
<li>the number of times a feature is used to split the data across all trees.</li>
</ul>
</li>
<li><code>gain</code> </li>
<li>用该特征进行决策树分割 基尼系数（或其他指标）的评价增加</li>
<li>the average gain of the feature when it is used in trees</li>
<li><code>cover</code> </li>
<li>the average coverage of the feature when it is used in trees</li>
<li><code>total_gain</code> </li>
<li>the total gain across all splits the feature is used in.</li>
<li><code>total_cover</code> </li>
<li>the total coverage across all splits the feature is used in.</li>
</ol>
<div class="hlcode"><pre><span class="n">score_dict</span><span class="o">=</span><span class="n">booster</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">fmap</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">score_dict</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="c"># {</span>
<span class="c">#     &quot;feature_1&quot;:100,</span>
<span class="c">#     &quot;feature_2&quot;:100,</span>
<span class="c">#     ...</span>
<span class="c"># }</span>

<span class="n">score_dict</span><span class="o">=</span><span class="n">booster</span><span class="o">.</span><span class="n">get_fscore</span><span class="p">(</span><span class="n">fmap</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">,</span> <span class="n">importance_type</span><span class="o">=</span><span class="s">&#39;weight&#39;</span><span class="p">)</span>

<span class="c"># 以下为 xgboost Sklearn API 的 特征重要性</span>
<span class="n">score_dict</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">booster</span><span class="p">()</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s">&#39;weight&#39;</span><span class="p">)</span>
<span class="n">score_dict</span><span class="o">=</span><span class="n">clf</span><span class="o">.</span><span class="n">get_booster</span><span class="p">()</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s">&quot;gain&quot;</span><span class="p">)</span>
<span class="n">score_dict</span><span class="o">=</span><span class="n">regr</span><span class="o">.</span><span class="n">get_booster</span><span class="p">()</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">importance_type</span><span class="o">=</span><span class="s">&quot;gain&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2020 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>