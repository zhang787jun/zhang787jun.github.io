<!DOCTYPE HTML>
<html>

<head>
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/Wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/Wiki/favicon.ico" type="image/x-icon">
    <title>Jupyter Notebooks on Kubernetes - Jun's personal knowledge wiki</title>
    <meta name="keywords" content="Technology, MachineLearning, DataMining, Wiki" />
    <meta name="description" content="A wiki website" />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
            }
        });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
</head>

<body>

    <div id="container">
        
<div id="header">
  <div id="post-nav"><a href="/Wiki/">Home</a>&nbsp;»&nbsp;<a href="/Wiki/#Virtualization_and_Cloud_Computing\3. Kubernetes容器集群管理\Kubernetes在高性能计算中的应用">Virtualization_and_Cloud_Computing\3. Kubernetes容器集群管理\Kubernetes在高性能计算中的应用</a>&nbsp;»&nbsp;Jupyter Notebooks on Kubernetes</div>
</div>
<div class="clearfix"></div>
<div id="title">Jupyter Notebooks on Kubernetes</div>
<div id="content">
  <h1 id="jupyter-notebooks-on-kubernetes">Jupyter Notebooks on Kubernetes</h1>
<h2 id="prerequisites">Prerequisites</h2>
<ul>
<li><a href="../1-docker">1 - Docker Basics</a></li>
<li><a href="../2-kubernetes">2 - Kubernetes Basics and cluster created</a></li>
<li><a href="../4-kubeflow">4 - Kubeflow</a></li>
</ul>
<h2 id="summary">Summary</h2>
<p>In this module, you will learn how to:</p>
<ul>
<li>Run Jupyter Notebooks locally using Docker</li>
<li>Run JupyterHub on Kubernetes using Kubeflow</li>
</ul>
<h2 id="how-jupyter-notebooks-work">How Jupyter Notebooks work</h2>
<p>The <a href="http://jupyter.org/">Jupyter Notebook</a> is an open source web application that allows users to create and share documents that contain live code, equations, visualizations, and narrative text for rapid prototyping. It is often used for data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and more. To better support exploratory iteration and to accelerate computation of Tensorflow jobs, let's look at how we can include data science tools like Jupyter Notebook with Docker and Kubernetes.</p>
<h2 id="how-jupyterhub-works">How JupyterHub works</h2>
<p>The <a href="https://jupyterhub.readthedocs.io/en/latest/">JupyterHub</a> is a multi-user Hub, spawns, manages, and proxies multiple instances of the single-user Jupyter notebook server. JupyterHub can be used to serve notebooks to a class of students, a corporate data science group, or a scientific research group. Let's look at how we can create JupyterHub to spawn multiple instances of Jupyter Notebook on Kubernetes using Kubeflow.</p>
<h2 id="exercises">Exercises</h2>
<h3 id="exercise-1-run-jupyter-notebooks-locally-using-docker">Exercise 1: Run Jupyter Notebooks locally using Docker</h3>
<p>In this first exercise, we will run Jupyter Notebooks locally using Docker. We will use the official tensorflow docker image as it comes with Jupyter notebook.</p>
<div class="hlcode"><pre><span class="go">docker run -it -p 8888:8888 tensorflow/tensorflow</span>
</pre></div>


<h4 id="validation">Validation</h4>
<p>To verify, browse to the url in the output log.</p>
<p>For example: <code>http://localhost:8888/?token=a3ea3cd914c5b68149e2b4a6d0220eca186fec41563c0413</code></p>
<h3 id="exercise-2-run-jupyterhub-on-kubernetes-using-kubeflow">Exercise 2: Run JupyterHub on Kubernetes using Kubeflow</h3>
<p>In this exercise, we will run JupyterHub to spawn multiple instances of Jupyter Notebooks on a Kubernetes cluster using Kubeflow.</p>
<div class="hlcode"><pre><span class="n">NAMESPACE</span><span class="o">=</span><span class="nx">kubeflow</span>
<span class="nx">kubectl</span> <span class="nb">get</span> <span class="nx">svc</span> <span class="na">-n</span><span class="o">=</span><span class="err">$</span><span class="p">{</span><span class="nx">NAMESPACE</span><span class="p">}</span>

<span class="nb">NAME</span>               <span class="k">TYPE</span>           <span class="nx">CLUSTER</span><span class="na">-IP</span>      <span class="nx">EXTERNAL</span><span class="na">-IP</span>   <span class="nb">PORT</span><span class="p">(</span><span class="nb">S</span><span class="p">)</span>        <span class="nx">AGE</span>
<span class="nx">...</span>
<span class="nx">jupyter</span><span class="o">-</span><span class="mi">0</span>                                <span class="nx">ClusterIP</span>   <span class="kc">None</span>           <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>        <span class="mi">8000</span><span class="p">/</span><span class="nx">TCP</span>            <span class="mi">132</span><span class="nx">m</span>
<span class="nx">jupyter</span><span class="na">-lb</span>                               <span class="nx">ClusterIP</span>   <span class="mf">10.0.191.68</span>    <span class="o">&lt;</span><span class="kc">none</span><span class="o">&gt;</span>        <span class="mi">80</span><span class="p">/</span><span class="nx">TCP</span>              <span class="mi">132</span><span class="nx">m</span>
</pre></div>


<p>To connect to the Kubeflow dashboard locally:</p>
<div class="hlcode"><pre>kubectl port-forward    svc/ambassador -n <span class="k">${</span><span class="nv">NAMESPACE</span><span class="k">}</span> 8080:80
</pre></div>


<p>Then navigate to JupyterHub: http://localhost:8080/hub</p>
<p>[Optional] To connect to your JupyterHub over a public IP:</p>
<p>To update the default service created for JupyterHub, run the following command to change the service to type LoadBalancer:</p>
<div class="hlcode"><pre><span class="nb">cd </span>ks_app
ks param <span class="nb">set </span>jupyter serviceType LoadBalancer
<span class="nb">cd</span> ..
<span class="k">${</span><span class="nv">KUBEFLOW_SOURCE</span><span class="k">}</span>/scripts/kfctl.sh apply k8s
</pre></div>


<p>创建一个新的Jupyter Notebook 实例<br />
- 浏览器打开hub<br />
- 登入<br />
- 点击<code>Start My Server</code> 按钮<br />
- 选择 images<br />
- CPU 内存限制</p>
<h1 id="distributed-tensorflow-with-kubernetes-and-tfjob">Distributed TensorFlow with Kubernetes and TFJob</h1>
<p>Thankfully, with Kubernetes and TFJob things are much, much simpler, making distributed training something you might actually be able to benefit from.</p>
<p>Before submitting a training job, you should have deployed Kubeflow to your cluster. Doing so ensures that the TFJob custom resource is available when you submit the training job.</p>
<ol>
<li>在集群中部署Kubeflow</li>
<li>TFJob 自定义资源</li>
</ol>
<p>Overview of TFJob distributed training<br />
So, how does TFJob work for distributed training? Let's look again at what the TFJobSpecand TFReplicaSpec objects looks like:<br />
TFJobSpec Object<br />
Field<br />
Type<br />
Description<br />
ReplicaSpecs<br />
TFReplicaSpec array<br />
Specification for a set of TensorFlow processes, defined below<br />
TFReplicaSpec Object<br />
Note the last parameter IsDefaultPS that we didn't talk about before.<br />
Field<br />
Type<br />
Description<br />
TfReplicaType<br />
string<br />
What type of replica are we defining? Can be MASTER, WORKER or PS. When not doing distributed TensorFlow, we just use MASTER which happens to be the default value.<br />
Replicas<br />
int<br />
Number of replicas of TfReplicaType. Again this is useful only for distributed TensorFLow. Default value is 1.<br />
Template<br />
PodTemplateSpec<br />
Describes the pod that will be created when executing a job. This is the standard Pod description that we have been using everywhere.<br />
IsDefaultPS<br />
boolean<br />
Whether the parameter server should be using a default image or a custom one (default to true)<br />
In case the distinction between master and workers is not clear, there is a single master per TensorFlow cluster, and it is in fact a worker. The difference is that the master is the worker that is going to handle the creation of the tf.Session, write logs and save the model.<br />
As you can see, TFJobSpec and TFReplicaSpec allow us to easily define the architecture of the TensorFlow cluster we would like to setup.<br />
Once we have defined this architecture in a TFJob template and deployed it with kubectl create, the operator will do most of the work for us. For each master, worker and parameter server in our TensorFlow cluster, the operator will create a service exposing it so they can communicate.<br />
It will then create an internal representation of the cluster with each node and it's associated internal DNS name.</p>
<p>For example, if you were to create a TFJob with 1 MASTER, 2 WORKERS and 1 PS, this representation would look similar to this:</p>
<div class="hlcode"><pre><span class="p">{</span>  
    <span class="nt">&quot;master&quot;</span><span class="p">:[</span>  
        <span class="s2">&quot;distributed-mnist-master-5oz2-0:2222&quot;</span>
    <span class="p">],</span>
    <span class="nt">&quot;ps&quot;</span><span class="p">:[</span>  
        <span class="s2">&quot;distributed-mnist-ps-5oz2-0:2222&quot;</span>
    <span class="p">],</span>
    <span class="nt">&quot;worker&quot;</span><span class="p">:[</span>  
        <span class="s2">&quot;distributed-mnist-worker-5oz2-0:2222&quot;</span><span class="p">,</span>
        <span class="s2">&quot;distributed-mnist-worker-5oz2-1:2222&quot;</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>


<p>Finally, the operator will create all the necessary pods, and in each one, inject an environment variable named Tf_CONFIG, containing the cluster specification above, as well as the respective job name and task id that each node of the TensorFlow cluster should assume.<br />
For example, here is the value of the TF_CONFIG environment variable that would be sent to worker 1:<br />
{<br />
   "cluster":{<br />
      "master":[<br />
         "distributed-mnist-master-5oz2-0:2222"<br />
      ],<br />
      "ps":[<br />
         "distributed-mnist-ps-5oz2-0:2222"<br />
      ],<br />
      "worker":[<br />
         "distributed-mnist-worker-5oz2-0:2222",<br />
         "distributed-mnist-worker-5oz2-1:2222"<br />
      ]<br />
   },<br />
   "task":{<br />
      "type":"worker",<br />
      "index":1<br />
   },<br />
   "environment":"cloud"<br />
}<br />
As you can see, this completely takes the responsibility of building and maintaining the ClusterSpec away from you. All you have to do, is modify your code to read the TF_CONFIG and act accordingly.<br />
Modifying your model to use TFJob's TF_CONFIG<br />
Concretely, let's see how you would modify your code:</p>
<h1 id="grab-the-tf_config-environment-variable">Grab the TF_CONFIG environment variable</h1>
<p>tf_config_json = os.environ.get("TF_CONFIG", "{}")</p>
<h1 id="deserialize-to-a-python-object">Deserialize to a python object</h1>
<p>tf_config = json.loads(tf_config_json)</p>
<h1 id="grab-the-cluster-specification-from-tf_config-and-create-a-new-tftrainclusterspec-instance-with-it">Grab the cluster specification from tf_config and create a new tf.train.ClusterSpec instance with it</h1>
<p>cluster_spec = tf_config.get("cluster", {})<br />
cluster_spec_object = tf.train.ClusterSpec(cluster_spec)</p>
<h1 id="grab-the-task-assigned-to-this-specific-process-from-the-config-job_name-might-be-worker-and-task_id-might-be-1-for-example">Grab the task assigned to this specific process from the config. job_name might be "worker" and task_id might be 1 for example</h1>
<p>task = tf_config.get("task", {})<br />
job_name = task["type"]<br />
task_id = task["index"]</p>
<h1 id="configure-the-tensorflow-server">Configure the TensorFlow server</h1>
<p>server_def = tf.train.ServerDef(<br />
    cluster=cluster_spec_object.as_cluster_def(),<br />
    protocol="grpc",<br />
    job_name=job_name,<br />
    task_index=task_id)<br />
server = tf.train.Server(server_def)</p>
<h1 id="checking-if-this-process-is-the-chief-also-called-master-the-master-has-the-responsibility-of-creating-the-session-saving-the-summaries-etc">checking if this process is the chief (also called master). The master has the responsibility of creating the session, saving the summaries etc.</h1>
<p>is_chief = (job_name == 'master')</p>
<h1 id="notice-that-we-are-not-handling-the-case-where-job_name-ps-that-is-because-tfjob-will-take-care-of-the-parameter-servers-for-us-by-default">Notice that we are not handling the case where job_name == 'ps'. That is because <code>TFJob</code> will take care of the parameter servers for us by default.</h1>
<p>As for any distributed TensorFlow training, you will then also need to modify your model to split the operations and variables among the workers and parameter servers as well as create on session on the master.<br />
Exercises<br />
1 - Modifying Our MNIST Example to Support Distributed Training<br />
1. a.<br />
Starting from the MNIST sample we have been working with so far, modify it to work with distributed TensorFlow and TFJob. You will then need to build the image and push it (you should push it under a different name or tag to avoid overwriting what you did before).<br />
cd 7-distributed-tensorflow/solution-src</p>
<h1 id="build-from-tensorflowtensorflowgpu-for-master-and-workers">build from tensorflow/tensorflow:gpu for master and workers</h1>
<p>docker build -t ${DOCKER_USERNAME}/tf-mnist:distributedgpu -f ./Dockerfile.gpu .</p>
<h1 id="builld-from-tensorflowtensorflow-for-the-parameter-server">builld from tensorflow/tensorflow for the parameter server</h1>
<p>docker build -t ${DOCKER_USERNAME}/tf-mnist:distributed .<br />
1. b.<br />
Modify the yaml template from module 6 - TFJob, to instead deploy 1 master, 2 workers and 1 PS. Then create a yaml to deploy TensorBoard to monitor the training with TensorBoard. Note that since our model is very simple, TensorFlow will likely use only 1 of the workers, but it will still work fine. Don't forget to update the image or tag.<br />
Validation<br />
kubectl get pods<br />
Should yield:<br />
NAME                                       READY     STATUS              RESTARTS   AGE<br />
module6-ex1-master-m8vi-0-rdr5o            1/1       Running   0          23s<br />
module6-ex1-ps-m8vi-0-0vhjm                1/1       Running   0          23s<br />
module6-ex1-worker-m8vi-0-eyb6l            1/1       Running   0          23s<br />
module6-ex1-worker-m8vi-1-bm2ue            1/1       Running   0          23s<br />
looking at the logs of the master with:<br />
kubectl logs <master-pod-name><br />
Should yield:<br />
[...]<br />
Initialize GrpcChannelCache for job master -&gt; {0 -&gt; localhost:2222}<br />
Initialize GrpcChannelCache for job ps -&gt; {0 -&gt; module6-ex1-ps-m8vi-0:2222}<br />
Initialize GrpcChannelCache for job worker -&gt; {0 -&gt; module6-ex1-worker-m8vi-0:2222, 1 -&gt; module6-ex1-worker-m8vi-1:2222}<br />
2018-04-30 22:45:28.963803: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:2222<br />
...</p>
<p>Accuracy at step 970: 0.9784<br />
Accuracy at step 980: 0.9791<br />
Accuracy at step 990: 0.9796<br />
Adding run metadata for 999<br />
This indicates that the ClusterSpec was correctly extracted from the environment variable and given to TensorFlow.<br />
Once the TensorBoard pod is provisioned and running, we can connect to it using:<br />
PODNAME=$(kubectl get pod -l app=tensorboard -o jsonpath='{.items[0].metadata.name}')<br />
kubectl port-forward ${PODNAME} 6006:6006<br />
From the browser, connect to it at http://127.0.0.1:6006, you should see that your model is indeed correctly distributed between workers and PS:</p>
<p>After a few minutes, the status of both worker nodes should show as Completed when doing kubectl get pods -a.<br />
Solution<br />
A working code sample is available in solution-src/main.py.<br />
TFJob's Template<br />
TensorBoard Template</p>
</div>
<div id="renote">
  <HR style=" FILTER: alpha (opacity = 100, finishopacity =0 , style= 3 )" width="80%" color=#987 cb 9 SIZE=3>
  <p>如果你觉得这篇文章对你有帮助，不妨请我喝杯咖啡，鼓励我创造更多!</p>
  <img src="/Wiki/static/images/pay.jpg" width="25%">
</div>

    </div>
    <div id="footer">
        <span>
            Copyright © 2020 zhang787jun.
            Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
        </span>
    </div>

    
</body>
<script>
    function changeImgurl(site_root_url) {
        var images = document.images;
        var site_root = site_root_url;
        for (i = 0, len = images.length; i < len; i++) {
            image = images[i];
            image_src = image.src;
            if (image_src.search("attach") >= 0) {
                re_image_src = image_src.slice(image_src.search("attach"));
                abs_image_src = (site_root.endsWith("/")) ? site_root + re_image_src : site_root + "/" +
                    re_image_src;
                image.src = abs_image_src;
            }
        }
    }
    var site_root_url = "/Wiki";
    changeImgurl(site_root_url);
    let isMathjaxConfig = false; // 防止重复调用Config，造成性能损耗
    const initMathjaxConfig = () => {
        if (!window.MathJax) {
            return;
        }
        window.MathJax.Hub.Config({
            showProcessingMessages: false, //关闭js加载过程信息
            messageStyle: "none", //不显示信息
            jax: ["input/TeX", "output/HTML-CSS"],
            tex2jax: {
                inlineMath: [["$", "$"], ["\\(", "\\)"]], //行内公式选择符
                displayMath: [["$$", "$$"], ["\\[", "\\]"]], //段内公式选择符
                skipTags: ["script", "noscript", "style", "textarea", "pre", "code", "a"] //避开某些标签
            },
            "HTML-CSS": {
                availableFonts: ["STIX", "TeX"], //可选字体
                showMathMenu: false //关闭右击菜单显示
            }
        });
        isMathjaxConfig = true; //
    };
    if (isMathjaxConfig === false) {
        // 如果：没有配置MathJax
        initMathjaxConfig();
    };
</script>

</html>